{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text classification (sentiment analysis)\n",
    "Task: Predict sentiment of Amazon reviews\n",
    "Dataset: Beans from TFDS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbbc77f284814682"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f0474e0967c03828"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Loading dataset & basic preprocessing\n",
    "- removal of reviews shorter than 5 characters\n",
    "- mapping from 1-5 -> 0,1,2\n",
    "- subsampling - without replacement, random state 42, 80 000 rows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ee5b5a6106d6686"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:45.824118Z",
     "start_time": "2024-05-20T07:13:41.605644500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 09:13:43.826634: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-20 09:13:43.826687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-20 09:13:43.867354: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-20 09:13:43.950213: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-20 09:13:44.934489: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from IPython.display import display\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.15.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:45.828117600Z",
     "start_time": "2024-05-20T07:13:45.815602900Z"
    }
   },
   "id": "ca34945a70395e1f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 09:13:46.123693: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:46.259826: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:46.259890: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:46.263803900Z",
     "start_time": "2024-05-20T07:13:45.860170200Z"
    }
   },
   "id": "4dd962ce90049d5a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/amazon_reviews_us_Major_Appliances_v1_00.tsv', sep='\\t', on_bad_lines='skip')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:47.165998500Z",
     "start_time": "2024-05-20T07:13:46.264801Z"
    }
   },
   "id": "41ff8b299de307d2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(96834, 15)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:47.185083500Z",
     "start_time": "2024-05-20T07:13:47.167504600Z"
    }
   },
   "id": "c630cd8ed64d4f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# remove nas and duplicate reviews\n",
    "df.dropna(axis=0, subset=['review_body'], inplace=True)\n",
    "df.drop_duplicates(subset=['review_body'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:47.264314Z",
     "start_time": "2024-05-20T07:13:47.217361300Z"
    }
   },
   "id": "861e0cae068fbc6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(93446, 15)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:47.268314200Z",
     "start_time": "2024-05-20T07:13:47.251770300Z"
    }
   },
   "id": "4761880489557793"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/balv05/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopword_list = nltk.corpus.stopwords.words(\"english\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:47.356383200Z",
     "start_time": "2024-05-20T07:13:47.310512900Z"
    }
   },
   "id": "296446ff70a87882"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def remove_tags(review):\n",
    "    return re.sub(pattern='<.*?>', string=review , repl=' ') \n",
    "\n",
    "def keep_alnum(review):\n",
    "    return re.sub(pattern='[^A-Za-z\\d\\s:]', string=review, repl=' ')\n",
    "\n",
    "def strip_spaces(review):\n",
    "    return re.sub(pattern='[\\s]{2,}', string=review, repl=' ')\n",
    "\n",
    "def lowercase(review):\n",
    "    return review.lower()\n",
    "\n",
    "def remove_stopwords(review):\n",
    "    review_list = review.split()\n",
    "    return \" \".join([word for word in review_list if word not in stopword_list])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:47.366980700Z",
     "start_time": "2024-05-20T07:13:47.359892300Z"
    }
   },
   "id": "feccec45640d371c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].apply(remove_tags)        # remove html tags\n",
    "df['review_body'] = df['review_body'].apply(keep_alnum)         # remove sub unicode char\n",
    "df['review_body'] = df['review_body'].apply(strip_spaces)       # strip all unnecessary whitespaces\n",
    "df['review_body'] = df['review_body'].apply(lowercase)          # put everything into lowercase\n",
    "df['review_body'] = df['review_body'].apply(remove_stopwords)   # put everything into lowercase\n",
    "df = df[df['review_body'].str.len() > 5]                        # keep only reviews longer than 5 characters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.321482300Z",
     "start_time": "2024-05-20T07:13:47.363971800Z"
    }
   },
   "id": "ab4b0c058041911e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      marketplace  customer_id       review_id  product_id  product_parent  \\\n0              US     16199106  R203HPW78Z7N4K  B0067WNSZY       633038551   \n1              US     16374060  R2EAIGVLEALSP3  B002QSXK60       811766671   \n2              US     15322085  R1K1CD73HHLILA  B00EC452R6       345562728   \n3              US     32004835  R2KZBMOFRMYOPO  B00MVVIF2G       563052763   \n4              US     25414497   R6BIZOZY6UD01  B00IY7BNUW       874236579   \n...           ...          ...             ...         ...             ...   \n96829          US     37431087  R3CYIDM3UEY5PA  B00005O64S       222987122   \n96830          US     44686434  R1PLFLGSA6N9WU  B00005O64T       802734810   \n96831          US     36739731   RBPARLMOY6ZU5  B00005O64S       222987122   \n96832          US     50744080   RSS5TDZOGUEB6  B00004SACT       344802997   \n96833          US     48699462  R1X5L2BT3H084O  B00004SACT       344802997   \n\n                                           product_title  product_category  \\\n0      FGGF3032MW Gallery Series 30\" Wide Freestandin...  Major Appliances   \n1                              Best Hand Clothes Wringer  Major Appliances   \n2                        Supco SET184 Thermal Cutoff Kit  Major Appliances   \n3      Midea WHS-160RB1 Compact Single Reversible Doo...  Major Appliances   \n4                          Avalon Bay Portable Ice Maker  Major Appliances   \n...                                                  ...               ...   \n96829  Haier HDT18PA Space Saver Compact Countertop D...  Major Appliances   \n96830  Haier America HSE02-WNAWW 1.8-Cubic-Foot Capac...  Major Appliances   \n96831  Haier HDT18PA Space Saver Compact Countertop D...  Major Appliances   \n96832         Sanyo Two-Door 2.9 Cubic Foot Refrigerator  Major Appliances   \n96833         Sanyo Two-Door 2.9 Cubic Foot Refrigerator  Major Appliances   \n\n       star_rating  helpful_votes  total_votes vine verified_purchase  \\\n0                5              0            0    N                 Y   \n1                5              1            1    N                 Y   \n2                5              0            0    N                 Y   \n3                5              1            1    N                 Y   \n4                5              0            0    N                 Y   \n...            ...            ...          ...  ...               ...   \n96829            4             37           43    N                 N   \n96830            1             33           39    N                 N   \n96831            5              6           45    N                 N   \n96832            4             71           71    N                 N   \n96833            3              8           40    N                 N   \n\n                                  review_headline  \\\n0      If you need a new stove, this is a winner.   \n1                                      Five Stars   \n2                                   Fast Shipping   \n3                                      Five Stars   \n4                                      Five Stars   \n...                                           ...   \n96829  Pretty good dishwasher for small apartment   \n96830                          Does not last long   \n96831                 Rave review for space saver   \n96832                  Sanyo compact refrigerator   \n96833                               a normal frig   \n\n                                             review_body review_date  \n0      great stove wonderful replacement sort antique...  2015-08-31  \n1                                           worked great  2015-08-31  \n2                   part exactly needed saved purchasing  2015-08-31  \n3      love refrigerator keeps everything cold recommend  2015-08-31  \n4                      running store ice works perfectly  2015-08-31  \n...                                                  ...         ...  \n96829  pretty good dishwasher price good job cleaning...  2002-07-14  \n96830  bought office extremely dissatisfied stopped w...  2002-06-03  \n96831  saw small dishwasher thought wonderful idea sm...  2002-05-05  \n96832  probably best small refrigerator market true f...  2000-09-29  \n96833  normal mid sized refrigerater good price reall...  2000-08-26  \n\n[92899 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>marketplace</th>\n      <th>customer_id</th>\n      <th>review_id</th>\n      <th>product_id</th>\n      <th>product_parent</th>\n      <th>product_title</th>\n      <th>product_category</th>\n      <th>star_rating</th>\n      <th>helpful_votes</th>\n      <th>total_votes</th>\n      <th>vine</th>\n      <th>verified_purchase</th>\n      <th>review_headline</th>\n      <th>review_body</th>\n      <th>review_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>US</td>\n      <td>16199106</td>\n      <td>R203HPW78Z7N4K</td>\n      <td>B0067WNSZY</td>\n      <td>633038551</td>\n      <td>FGGF3032MW Gallery Series 30\" Wide Freestandin...</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>If you need a new stove, this is a winner.</td>\n      <td>great stove wonderful replacement sort antique...</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>US</td>\n      <td>16374060</td>\n      <td>R2EAIGVLEALSP3</td>\n      <td>B002QSXK60</td>\n      <td>811766671</td>\n      <td>Best Hand Clothes Wringer</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Five Stars</td>\n      <td>worked great</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>US</td>\n      <td>15322085</td>\n      <td>R1K1CD73HHLILA</td>\n      <td>B00EC452R6</td>\n      <td>345562728</td>\n      <td>Supco SET184 Thermal Cutoff Kit</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Fast Shipping</td>\n      <td>part exactly needed saved purchasing</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>US</td>\n      <td>32004835</td>\n      <td>R2KZBMOFRMYOPO</td>\n      <td>B00MVVIF2G</td>\n      <td>563052763</td>\n      <td>Midea WHS-160RB1 Compact Single Reversible Doo...</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Five Stars</td>\n      <td>love refrigerator keeps everything cold recommend</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>US</td>\n      <td>25414497</td>\n      <td>R6BIZOZY6UD01</td>\n      <td>B00IY7BNUW</td>\n      <td>874236579</td>\n      <td>Avalon Bay Portable Ice Maker</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Five Stars</td>\n      <td>running store ice works perfectly</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96829</th>\n      <td>US</td>\n      <td>37431087</td>\n      <td>R3CYIDM3UEY5PA</td>\n      <td>B00005O64S</td>\n      <td>222987122</td>\n      <td>Haier HDT18PA Space Saver Compact Countertop D...</td>\n      <td>Major Appliances</td>\n      <td>4</td>\n      <td>37</td>\n      <td>43</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Pretty good dishwasher for small apartment</td>\n      <td>pretty good dishwasher price good job cleaning...</td>\n      <td>2002-07-14</td>\n    </tr>\n    <tr>\n      <th>96830</th>\n      <td>US</td>\n      <td>44686434</td>\n      <td>R1PLFLGSA6N9WU</td>\n      <td>B00005O64T</td>\n      <td>802734810</td>\n      <td>Haier America HSE02-WNAWW 1.8-Cubic-Foot Capac...</td>\n      <td>Major Appliances</td>\n      <td>1</td>\n      <td>33</td>\n      <td>39</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Does not last long</td>\n      <td>bought office extremely dissatisfied stopped w...</td>\n      <td>2002-06-03</td>\n    </tr>\n    <tr>\n      <th>96831</th>\n      <td>US</td>\n      <td>36739731</td>\n      <td>RBPARLMOY6ZU5</td>\n      <td>B00005O64S</td>\n      <td>222987122</td>\n      <td>Haier HDT18PA Space Saver Compact Countertop D...</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>6</td>\n      <td>45</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Rave review for space saver</td>\n      <td>saw small dishwasher thought wonderful idea sm...</td>\n      <td>2002-05-05</td>\n    </tr>\n    <tr>\n      <th>96832</th>\n      <td>US</td>\n      <td>50744080</td>\n      <td>RSS5TDZOGUEB6</td>\n      <td>B00004SACT</td>\n      <td>344802997</td>\n      <td>Sanyo Two-Door 2.9 Cubic Foot Refrigerator</td>\n      <td>Major Appliances</td>\n      <td>4</td>\n      <td>71</td>\n      <td>71</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Sanyo compact refrigerator</td>\n      <td>probably best small refrigerator market true f...</td>\n      <td>2000-09-29</td>\n    </tr>\n    <tr>\n      <th>96833</th>\n      <td>US</td>\n      <td>48699462</td>\n      <td>R1X5L2BT3H084O</td>\n      <td>B00004SACT</td>\n      <td>344802997</td>\n      <td>Sanyo Two-Door 2.9 Cubic Foot Refrigerator</td>\n      <td>Major Appliances</td>\n      <td>3</td>\n      <td>8</td>\n      <td>40</td>\n      <td>N</td>\n      <td>N</td>\n      <td>a normal frig</td>\n      <td>normal mid sized refrigerater good price reall...</td>\n      <td>2000-08-26</td>\n    </tr>\n  </tbody>\n</table>\n<p>92899 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.335345900Z",
     "start_time": "2024-05-20T07:13:54.311955300Z"
    }
   },
   "id": "633603daaf3937ff"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df.loc[df['star_rating'] < 3, 'sentiment'] = 0\n",
    "df.loc[df['star_rating'] == 3, 'sentiment'] = 1\n",
    "df.loc[df['star_rating'] > 3, 'sentiment'] = 2\n",
    "df['sentiment'] = df['sentiment'].astype('int')\n",
    "df.drop('star_rating', axis=1, inplace=True)\n",
    "df = resample(df, n_samples=80000, random_state=42, replace=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.414980200Z",
     "start_time": "2024-05-20T07:13:54.326478600Z"
    }
   },
   "id": "174a2be074f5703"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      marketplace  customer_id       review_id  product_id  product_parent  \\\n71963          US     23022807  R3IZQ5QBR0C7B7  B0039V7JFG       184993957   \n15508          US     21831333  R2LGGHUB944XMT  B00EJPHJVK       516641616   \n3110           US     11941986  R21U3YZPS3MBXG  B00HH2YZT6        73366442   \n88804          US     46476694  R2JZ0YSJ5QEZX4  B001VKY8GU       232040651   \n18295          US     48338607  R2QENB1J5LBM14  B00MZH0OPC       394118467   \n...           ...          ...             ...         ...             ...   \n62973          US     31634986  R173X6QPB1N8SY  B004HXDLJ8       693470227   \n45682          US     52949439   R4YB9KY26NLPP  B003GFAY52       647457047   \n84940          US     42829199  R1W9QEUT7MIYGD  B004WP4BAO       480751909   \n1873           US     19293947  R12LFU2ZVPAZSS  B0125S2K0M       504103070   \n53872          US     11233134  R2S04Z77YZXZAP  B007VXJ0HS       285649250   \n\n                                           product_title  product_category  \\\n71963            LG 3.6 CF FRONT LOAD WASHER DRYER COMBO  Major Appliances   \n15508  Fantech Lint Trap for Dryer Booster - DBLT4W (...  Major Appliances   \n3110   Samsung RF32FMQDBSR 4-Door Refrigerator with C...  Major Appliances   \n88804           Koolatron Coca Cola Personal Cube Fridge  Major Appliances   \n18295  ( 2 PACK ) 3392519 - DRYER THERMAL FUSE for Wh...  Major Appliances   \n...                                                  ...               ...   \n62973  Whynter BWR-18SD 18 Bottle Built-In Wine Refri...  Major Appliances   \n45682         Broan 30W in. QP2 Under Cabinet Range Hood  Major Appliances   \n84940                                  Samsung DV5451AGW  Major Appliances   \n1873   Avalon Top Loading Water Cooler Dispenser - Ho...  Major Appliances   \n53872  LG LDF7561 Fully Integrated Dishwasher with He...  Major Appliances   \n\n       helpful_votes  total_votes vine verified_purchase  \\\n71963              5           14    N                 N   \n15508              0            0    N                 Y   \n3110               6            6    N                 N   \n88804              0            0    N                 N   \n18295              0            0    N                 Y   \n...              ...          ...  ...               ...   \n62973             11           12    N                 Y   \n45682              9            9    N                 Y   \n84940              4            4    N                 N   \n1873             144          156    N                 N   \n53872              0            1    N                 N   \n\n                                         review_headline  \\\n71963                          lg small washer/dryer set   \n15508  very hard to open must be securely mounted no ...   \n3110   15 month useful life - this should be disconti...   \n88804                               Unexpectedly Awesome   \n18295                                            Perfect   \n...                                                  ...   \n62973                                         Very Happy   \n45682  Up until it quit working I though I had made a...   \n84940      Does NOT dry clothes. So not much of a dryer.   \n1873   Avalon water dispenser beat my many previous w...   \n53872                                  Bad build quality   \n\n                                             review_body review_date  \\\n71963  usually rate things hate exactly feel small lg...  2013-04-06   \n15508         hard open must securely mounted provisions  2015-04-16   \n3110   15 months stopped working threw groceries call...  2015-08-07   \n88804  silver version tiny cooler fridge company chri...  2011-06-28   \n18295                      exactly needed get dryer back  2015-03-22   \n...                                                  ...         ...   \n62973  purchased replace space 12 34 garbage compacto...  2013-09-28   \n45682  bought item professionally installed middle ap...  2014-07-07   \n84940  purchased nice looking supposedly good name br...  2012-02-18   \n1873   videoid:8829556f67d2453e377e6459465db27e first...  2015-08-16   \n53872  middle drawer tight pull easily tech take look...  2014-03-01   \n\n       sentiment  \n71963          0  \n15508          1  \n3110           0  \n88804          2  \n18295          2  \n...          ...  \n62973          2  \n45682          0  \n84940          0  \n1873           2  \n53872          0  \n\n[80000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>marketplace</th>\n      <th>customer_id</th>\n      <th>review_id</th>\n      <th>product_id</th>\n      <th>product_parent</th>\n      <th>product_title</th>\n      <th>product_category</th>\n      <th>helpful_votes</th>\n      <th>total_votes</th>\n      <th>vine</th>\n      <th>verified_purchase</th>\n      <th>review_headline</th>\n      <th>review_body</th>\n      <th>review_date</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>71963</th>\n      <td>US</td>\n      <td>23022807</td>\n      <td>R3IZQ5QBR0C7B7</td>\n      <td>B0039V7JFG</td>\n      <td>184993957</td>\n      <td>LG 3.6 CF FRONT LOAD WASHER DRYER COMBO</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>14</td>\n      <td>N</td>\n      <td>N</td>\n      <td>lg small washer/dryer set</td>\n      <td>usually rate things hate exactly feel small lg...</td>\n      <td>2013-04-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15508</th>\n      <td>US</td>\n      <td>21831333</td>\n      <td>R2LGGHUB944XMT</td>\n      <td>B00EJPHJVK</td>\n      <td>516641616</td>\n      <td>Fantech Lint Trap for Dryer Booster - DBLT4W (...</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>very hard to open must be securely mounted no ...</td>\n      <td>hard open must securely mounted provisions</td>\n      <td>2015-04-16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3110</th>\n      <td>US</td>\n      <td>11941986</td>\n      <td>R21U3YZPS3MBXG</td>\n      <td>B00HH2YZT6</td>\n      <td>73366442</td>\n      <td>Samsung RF32FMQDBSR 4-Door Refrigerator with C...</td>\n      <td>Major Appliances</td>\n      <td>6</td>\n      <td>6</td>\n      <td>N</td>\n      <td>N</td>\n      <td>15 month useful life - this should be disconti...</td>\n      <td>15 months stopped working threw groceries call...</td>\n      <td>2015-08-07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>88804</th>\n      <td>US</td>\n      <td>46476694</td>\n      <td>R2JZ0YSJ5QEZX4</td>\n      <td>B001VKY8GU</td>\n      <td>232040651</td>\n      <td>Koolatron Coca Cola Personal Cube Fridge</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Unexpectedly Awesome</td>\n      <td>silver version tiny cooler fridge company chri...</td>\n      <td>2011-06-28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18295</th>\n      <td>US</td>\n      <td>48338607</td>\n      <td>R2QENB1J5LBM14</td>\n      <td>B00MZH0OPC</td>\n      <td>394118467</td>\n      <td>( 2 PACK ) 3392519 - DRYER THERMAL FUSE for Wh...</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Perfect</td>\n      <td>exactly needed get dryer back</td>\n      <td>2015-03-22</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>62973</th>\n      <td>US</td>\n      <td>31634986</td>\n      <td>R173X6QPB1N8SY</td>\n      <td>B004HXDLJ8</td>\n      <td>693470227</td>\n      <td>Whynter BWR-18SD 18 Bottle Built-In Wine Refri...</td>\n      <td>Major Appliances</td>\n      <td>11</td>\n      <td>12</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Very Happy</td>\n      <td>purchased replace space 12 34 garbage compacto...</td>\n      <td>2013-09-28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>45682</th>\n      <td>US</td>\n      <td>52949439</td>\n      <td>R4YB9KY26NLPP</td>\n      <td>B003GFAY52</td>\n      <td>647457047</td>\n      <td>Broan 30W in. QP2 Under Cabinet Range Hood</td>\n      <td>Major Appliances</td>\n      <td>9</td>\n      <td>9</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Up until it quit working I though I had made a...</td>\n      <td>bought item professionally installed middle ap...</td>\n      <td>2014-07-07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>84940</th>\n      <td>US</td>\n      <td>42829199</td>\n      <td>R1W9QEUT7MIYGD</td>\n      <td>B004WP4BAO</td>\n      <td>480751909</td>\n      <td>Samsung DV5451AGW</td>\n      <td>Major Appliances</td>\n      <td>4</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Does NOT dry clothes. So not much of a dryer.</td>\n      <td>purchased nice looking supposedly good name br...</td>\n      <td>2012-02-18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1873</th>\n      <td>US</td>\n      <td>19293947</td>\n      <td>R12LFU2ZVPAZSS</td>\n      <td>B0125S2K0M</td>\n      <td>504103070</td>\n      <td>Avalon Top Loading Water Cooler Dispenser - Ho...</td>\n      <td>Major Appliances</td>\n      <td>144</td>\n      <td>156</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Avalon water dispenser beat my many previous w...</td>\n      <td>videoid:8829556f67d2453e377e6459465db27e first...</td>\n      <td>2015-08-16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>53872</th>\n      <td>US</td>\n      <td>11233134</td>\n      <td>R2S04Z77YZXZAP</td>\n      <td>B007VXJ0HS</td>\n      <td>285649250</td>\n      <td>LG LDF7561 Fully Integrated Dishwasher with He...</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Bad build quality</td>\n      <td>middle drawer tight pull easily tech take look...</td>\n      <td>2014-03-01</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.438056900Z",
     "start_time": "2024-05-20T07:13:54.367233200Z"
    }
   },
   "id": "61075fa8ce779b40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Final dataset\n",
    "- 80 000 instances\n",
    "- NEGATIVE 21 334\n",
    "- NEUTRAL 5 674\n",
    "- POSITIVE 52 992 \n",
    "- **Quite imbalanced -> experiment with class weights**\n",
    "- 90:10 train:test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f66880c2eaddb91e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n2    52992\n0    21334\n1     5674\nName: count, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.439566800Z",
     "start_time": "2024-05-20T07:13:54.377828700Z"
    }
   },
   "id": "51a301bdbbc85fa6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "df_multimodal = df\n",
    "df = df[['review_body', 'sentiment']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review_body'], df['sentiment'], random_state=42, test_size=0.1, stratify=df['sentiment']\n",
    ")\n",
    "#Train-val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.483366400Z",
     "start_time": "2024-05-20T07:13:54.386347400Z"
    }
   },
   "id": "3f410caa3e666495"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n2    42924\n0    17280\n1     4596\nName: count, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.983435200Z",
     "start_time": "2024-05-19T18:19:07.967807Z"
    }
   },
   "id": "f665ddc4246c79dc"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n2    5299\n0    2134\n1     567\nName: count, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.983435200Z",
     "start_time": "2024-05-19T18:19:07.971921Z"
    }
   },
   "id": "bb12164d07568651"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Recurrent Neural Network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb0864a37a48ec44"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 09:13:54.427989: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:54.428072: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:54.428110: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:54.589302: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:54.589387: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:54.589394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-20 09:13:54.589442: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-20 09:13:54.589456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:0b:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:13:54.851272700Z",
     "start_time": "2024-05-20T07:13:54.840758500Z"
    }
   },
   "id": "96e28c1a9c77e91f"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "max_tokens = 8000\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    ngrams=1,\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "\n",
    "text_only_train_ds = train_dataset.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:36.380155100Z",
     "start_time": "2024-05-20T07:13:54.853278100Z"
    }
   },
   "id": "f97e30531d7c3605"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['', '[UNK]', 'one', 'water', 'would', 'great', 'like', 'get',\n       'unit', 'ice', 'time', 'use', 'machine', 'well', 'good', 'washer',\n       'product', 'works', 'new', '2'], dtype='<U15')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(text_vectorization.get_vocabulary())\n",
    "vocab[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:53.400162200Z",
     "start_time": "2024-05-19T18:22:53.391791500Z"
    }
   },
   "id": "f0b6e642b87c8ac5"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Define a function to vectorize the texts\n",
    "def vectorize_text(text, label):\n",
    "    return text_vectorization(text), label\n",
    "\n",
    "# Apply the vectorization to the training, validation, and test datasets\n",
    "train_ds = (train_dataset.map(vectorize_text).cache()\n",
    "            .shuffle(10000)\n",
    "            .batch(32)\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "val_ds = (validation_dataset.map(vectorize_text)\n",
    "          .cache()\n",
    "          .batch(32)\n",
    "          .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "test_ds = (test_dataset.map(vectorize_text)\n",
    "           .cache()\n",
    "           .batch(32)\n",
    "           .prefetch(buffer_size=tf.data.AUTOTUNE))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:36.537310600Z",
     "start_time": "2024-05-20T07:17:36.393674900Z"
    }
   },
   "id": "b7526999eb3cc981"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs data type <dtype: 'int64'>\n",
      "inputs shape (32, 100)\n",
      "targets data type <dtype: 'int64'>\n",
      "targets shape (32,)\n",
      "inputs[0] tf.Tensor(\n",
      "[[ 738  805  500 ...  152    1   28]\n",
      " [2365   32  193 ...    0    0    0]\n",
      " [6081    1  331 ...    0    0    0]\n",
      " ...\n",
      " [  55    9  151 ...    0    0    0]\n",
      " [1024  659 3231 ...    0    0    0]\n",
      " [  27  170  738 ...    0    0    0]], shape=(32, 100), dtype=int64)\n",
      "targets[0] tf.Tensor([2 2 2 2 2 2 2 2 2 0 0 2 1 2 0 0 2 2 1 2 2 0 2 2 2 1 2 2 0 2 0 0], shape=(32,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 09:17:37.841925: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs data type\",inputs.dtype)\n",
    "    print(\"inputs shape\",inputs.shape)\n",
    "    print(\"targets data type\",targets.dtype)\n",
    "    print(\"targets shape\",targets.shape)\n",
    "    print(\"inputs[0]\", inputs)\n",
    "    #print(inputs[0].numpy().decode('utf-8'))\n",
    "    print(\"targets[0]\", targets)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:37.847967200Z",
     "start_time": "2024-05-20T07:17:36.540589200Z"
    }
   },
   "id": "f882d9aa66e1ba65"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "negative, neutral, positive = np.bincount(df['sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:37.854672500Z",
     "start_time": "2024-05-20T07:17:37.849502400Z"
    }
   },
   "id": "6b3a385080e2f412"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "(21334, 5674, 52992)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative, neutral, positive"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:37.868200600Z",
     "start_time": "2024-05-20T07:17:37.851610800Z"
    }
   },
   "id": "7b169e55dc72c381"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.25\n",
      "Weight for class 1: 4.70\n",
      "Weight for class 2: 0.50\n"
     ]
    }
   ],
   "source": [
    "### proportional calculation of weights \n",
    "\n",
    "weight_for_0 = (1 / negative) * (df.shape[0] / 3)\n",
    "weight_for_1 = (1 / neutral) * (df.shape[0] / 3)\n",
    "weight_for_2 = (1 / positive) * (df.shape[0] / 3)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "print('Weight for class 2: {:.2f}'.format(weight_for_2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:37.869200900Z",
     "start_time": "2024-05-20T07:17:37.864187900Z"
    }
   },
   "id": "ead80fe388cbe495"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "def get_conf_matrix(model):\n",
    "    predictions = model.predict(test_ds)\n",
    "    classes = tf.argmax(predictions, axis=-1)\n",
    "    intensity = confusion_matrix(y_test, list(classes.numpy()))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = intensity, display_labels=[0,1,2])\n",
    "    disp.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:37.937375700Z",
     "start_time": "2024-05-20T07:17:37.869200900Z"
    }
   },
   "id": "921139b146fe469b"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def create_RNN(max_length, embedding_dim = 128, lstm_units = 16, optimizer = 'sgd', metrics = 'accuracy'):\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "\n",
    "    x = layers.Embedding(max_tokens, embedding_dim)(inputs)\n",
    "\n",
    "    # Bidirectional LSTM layer\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units))(x)\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    outputs = layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[metrics])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_CNN(max_length, embedding_dim = 128, dropout_rate = 0.5, optimizer = 'sgd', metrics = 'accuracy', activation = 'relu'):\n",
    "\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "\n",
    "    x = layers.Embedding(max_tokens, embedding_dim, input_length=max_length)(inputs)\n",
    "    x = layers.Conv1D(filters = 128, kernel_size =  5, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=4, padding='same', activation=activation)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=4, padding='same', activation=activation)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=4, padding='same', activation=activation)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dense(10, activation = 'sigmoid')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    outputs = layers.Dense(3, activation = 'sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[metrics])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:17:37.948297Z",
     "start_time": "2024-05-20T07:17:37.876201900Z"
    }
   },
   "id": "fb777943bfdfa9b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Train Reccurent Neural Network\n",
    "- train baseline model with basic parameters\n",
    "- train baseline model with basic parameters + adjusted weights\n",
    "- implement hyperparameter tuning using TFDF "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c815af443cec87e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 RNN with default weights and default hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11f4ec4713a7667f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:22:55.110693: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          1024000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 32)                18560     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1042659 (3.98 MB)\n",
      "Trainable params: 1042659 (3.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:22:58.298016: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-19 20:22:58.373692: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f03e9ad73e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-19 20:22:58.373726: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716142978.399132  410299 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 54s 25ms/step - loss: 0.8086 - accuracy: 0.6624 - val_loss: 0.7901 - val_accuracy: 0.6624\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7620 - accuracy: 0.6627 - val_loss: 0.7359 - val_accuracy: 0.6821\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6886 - accuracy: 0.7297 - val_loss: 0.6119 - val_accuracy: 0.7711\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.5784 - accuracy: 0.7899 - val_loss: 0.6455 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.5204 - accuracy: 0.8169 - val_loss: 0.5817 - val_accuracy: 0.7808\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4868 - accuracy: 0.8309 - val_loss: 0.5733 - val_accuracy: 0.7885\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.4635 - accuracy: 0.8393 - val_loss: 0.5592 - val_accuracy: 0.7981\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4466 - accuracy: 0.8448 - val_loss: 0.5271 - val_accuracy: 0.8125\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.4346 - accuracy: 0.8493 - val_loss: 0.5126 - val_accuracy: 0.8174\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.4255 - accuracy: 0.8526 - val_loss: 0.5175 - val_accuracy: 0.8183\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.4179 - accuracy: 0.8558 - val_loss: 0.5400 - val_accuracy: 0.8131\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4118 - accuracy: 0.8577 - val_loss: 0.5488 - val_accuracy: 0.8128\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.5140 - accuracy: 0.8169\n",
      "Test dataset accuracy: 0.8168749809265137\n",
      "250/250 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_RNN(max_length)\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.002, restore_best_weights=True),\n",
    "]\n",
    "history = model.fit(train_ds.cache(), epochs=20, validation_data=val_ds.cache(), callbacks=callbacks)\n",
    "print(f\"Test dataset accuracy: {model.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:31:01.279802800Z",
     "start_time": "2024-05-19T18:22:55.028425600Z"
    }
   },
   "id": "1f479272e4a3fe33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 RNN with adjusted weights and default hyperparameters\n",
    "- Weight for class 0: 1.25\n",
    "- Weight for class 1: 4.70\n",
    "- Weight for class 2: 0.50\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6f1c968efbe62e8"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 128)          1024000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 32)                18560     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1042659 (3.98 MB)\n",
      "Trainable params: 1042659 (3.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 52s 25ms/step - loss: 1.0756 - accuracy: 0.5161 - val_loss: 1.0391 - val_accuracy: 0.5726\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0341 - accuracy: 0.6031 - val_loss: 0.9645 - val_accuracy: 0.6336\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9414 - accuracy: 0.6702 - val_loss: 0.8931 - val_accuracy: 0.6514\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.8537 - accuracy: 0.6868 - val_loss: 0.8152 - val_accuracy: 0.6329\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8015 - accuracy: 0.6928 - val_loss: 0.7885 - val_accuracy: 0.6189\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7700 - accuracy: 0.6960 - val_loss: 0.7524 - val_accuracy: 0.6344\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7469 - accuracy: 0.7052 - val_loss: 0.7676 - val_accuracy: 0.6162\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7291 - accuracy: 0.7092 - val_loss: 0.6574 - val_accuracy: 0.7060\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7153 - accuracy: 0.7112 - val_loss: 0.6677 - val_accuracy: 0.6899\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.6981 - accuracy: 0.7173 - val_loss: 0.6823 - val_accuracy: 0.6772\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6865 - accuracy: 0.7215 - val_loss: 0.6591 - val_accuracy: 0.6953\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.6551 - accuracy: 0.7079\n",
      "Test dataset accuracy: 0.7078750133514404\n",
      "250/250 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "model = create_RNN(max_length, embedding_dim)\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.002, restore_best_weights=True),\n",
    "]\n",
    "history = model.fit(train_ds.cache(), epochs=20, validation_data=val_ds.cache(), callbacks=callbacks, class_weight=class_weight)\n",
    "print(f\"Test dataset accuracy: {model.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:30.558952700Z",
     "start_time": "2024-05-19T18:31:01.279802800Z"
    }
   },
   "id": "811dc9379204510c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. RNN with hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5729d8fab009b6d"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def grid_search_RNN(epochs=20, patience=3):\n",
    "    best_model = None\n",
    "    best_accuracy = 0.0\n",
    "    print(f\"Need to train {len(param_grid_RNN['embedding_dim'])*len(param_grid_RNN['embedding_dim'])*len(param_grid_RNN['optimizer'])} RNNs.\")\n",
    "    count = 0\n",
    "    for embedding_dim in param_grid_RNN['embedding_dim']:\n",
    "        for lstm_unit in param_grid_RNN['lstm_units']:\n",
    "            for optimizer in param_grid_RNN['optimizer']:\n",
    "                model = create_RNN(max_length=max_length,\n",
    "                                   embedding_dim=embedding_dim,\n",
    "                                   lstm_units = lstm_unit,\n",
    "                                   optimizer=optimizer)\n",
    "\n",
    "                callbacks = [\n",
    "                    keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "                ]\n",
    "\n",
    "                history = model.fit(train_ds.cache(), epochs=epochs,\n",
    "                                    validation_data=val_ds.cache(),\n",
    "                                    callbacks=callbacks,\n",
    "                                    class_weight=class_weight)\n",
    "\n",
    "                val_acc = history.history['val_accuracy'][-1]  # Get last validation accuracy\n",
    "                count+=1\n",
    "                print(f\"{count}/{len(param_grid_RNN['embedding_dim'])*len(param_grid_RNN['embedding_dim'])*len(param_grid_RNN['optimizer'])}\")\n",
    "                if val_acc > best_accuracy:\n",
    "                    best_model = model\n",
    "                    best_accuracy = val_acc\n",
    "    return best_model, best_accuracy\n",
    "\n",
    "# Example usage (assuming you have prepared your train_data and val_data)\n",
    "\n",
    "# Example usage (assuming you have your training data)\n",
    "param_grid_RNN = {\n",
    "    'embedding_dim': [64, 128, 256],\n",
    "    'lstm_units': [16, 32, 64],\n",
    "    'optimizer': ['adam', 'sgd', 'adagrad'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T07:19:57.317275800Z",
     "start_time": "2024-05-20T07:19:57.272536500Z"
    }
   },
   "id": "bc68a6ea6a7536d3"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to train 27 RNNs.\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 65s 30ms/step - loss: 0.7393 - accuracy: 0.7245 - val_loss: 0.5868 - val_accuracy: 0.7472\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.5821 - accuracy: 0.7776 - val_loss: 0.6185 - val_accuracy: 0.7393\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4955 - accuracy: 0.8141 - val_loss: 0.5636 - val_accuracy: 0.7782\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.4182 - accuracy: 0.8417 - val_loss: 0.5642 - val_accuracy: 0.7940\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.3587 - accuracy: 0.8623 - val_loss: 0.7076 - val_accuracy: 0.7414\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.3125 - accuracy: 0.8796 - val_loss: 0.6078 - val_accuracy: 0.8068\n",
      "1/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 53s 25ms/step - loss: 1.0894 - accuracy: 0.4112 - val_loss: 1.0584 - val_accuracy: 0.5854\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0545 - accuracy: 0.5858 - val_loss: 1.0291 - val_accuracy: 0.5986\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0265 - accuracy: 0.6082 - val_loss: 1.1155 - val_accuracy: 0.5562\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9436 - accuracy: 0.6613 - val_loss: 1.1148 - val_accuracy: 0.5838\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9052 - accuracy: 0.6703 - val_loss: 0.8647 - val_accuracy: 0.6831\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8231 - accuracy: 0.6956 - val_loss: 0.7803 - val_accuracy: 0.6917\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7857 - accuracy: 0.7006 - val_loss: 0.7637 - val_accuracy: 0.6896\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.7586 - accuracy: 0.7058 - val_loss: 0.7891 - val_accuracy: 0.6457\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7374 - accuracy: 0.7101 - val_loss: 0.6971 - val_accuracy: 0.6993\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.7198 - accuracy: 0.7152 - val_loss: 0.7444 - val_accuracy: 0.6657\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6999 - accuracy: 0.7257 - val_loss: 0.7716 - val_accuracy: 0.6607\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.6852 - accuracy: 0.7309 - val_loss: 0.8405 - val_accuracy: 0.6208\n",
      "2/27\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 09:32:28.994708: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 59s 28ms/step - loss: 1.0951 - accuracy: 0.5667 - val_loss: 1.0775 - val_accuracy: 0.6435\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0873 - accuracy: 0.6470 - val_loss: 1.0590 - val_accuracy: 0.6332\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0719 - accuracy: 0.6260 - val_loss: 1.0368 - val_accuracy: 0.6256\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0593 - accuracy: 0.6214 - val_loss: 1.0310 - val_accuracy: 0.6207\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0530 - accuracy: 0.6181 - val_loss: 1.0269 - val_accuracy: 0.6168\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0483 - accuracy: 0.6176 - val_loss: 1.0221 - val_accuracy: 0.6168\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0437 - accuracy: 0.6192 - val_loss: 1.0163 - val_accuracy: 0.6187\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0388 - accuracy: 0.6222 - val_loss: 1.0094 - val_accuracy: 0.6246\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0331 - accuracy: 0.6277 - val_loss: 1.0010 - val_accuracy: 0.6310\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 1.0262 - accuracy: 0.6356 - val_loss: 0.9909 - val_accuracy: 0.6379\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0176 - accuracy: 0.6459 - val_loss: 0.9785 - val_accuracy: 0.6508\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0060 - accuracy: 0.6615 - val_loss: 0.9632 - val_accuracy: 0.6696\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.9881 - accuracy: 0.6861 - val_loss: 0.9397 - val_accuracy: 0.6997\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9558 - accuracy: 0.7342 - val_loss: 0.9073 - val_accuracy: 0.7336\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9300 - accuracy: 0.7610 - val_loss: 0.8730 - val_accuracy: 0.7524\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9136 - accuracy: 0.7687 - val_loss: 0.8509 - val_accuracy: 0.7590\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8998 - accuracy: 0.7733 - val_loss: 0.8327 - val_accuracy: 0.7622\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8877 - accuracy: 0.7758 - val_loss: 0.8167 - val_accuracy: 0.7635\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8770 - accuracy: 0.7773 - val_loss: 0.8022 - val_accuracy: 0.7681\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8672 - accuracy: 0.7784 - val_loss: 0.7890 - val_accuracy: 0.7715\n",
      "3/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 62s 30ms/step - loss: 0.7462 - accuracy: 0.7139 - val_loss: 0.6411 - val_accuracy: 0.6824\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.5943 - accuracy: 0.7743 - val_loss: 0.5932 - val_accuracy: 0.7431\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.5148 - accuracy: 0.8078 - val_loss: 0.5689 - val_accuracy: 0.7665\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.4333 - accuracy: 0.8350 - val_loss: 0.6477 - val_accuracy: 0.7465\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.3713 - accuracy: 0.8590 - val_loss: 0.6025 - val_accuracy: 0.7856\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.3171 - accuracy: 0.8776 - val_loss: 0.6430 - val_accuracy: 0.7890\n",
      "4/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 51s 25ms/step - loss: 1.0893 - accuracy: 0.4575 - val_loss: 1.0411 - val_accuracy: 0.5835\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0540 - accuracy: 0.5858 - val_loss: 1.0194 - val_accuracy: 0.5917\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0289 - accuracy: 0.6087 - val_loss: 0.9870 - val_accuracy: 0.5765\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9376 - accuracy: 0.6660 - val_loss: 0.8939 - val_accuracy: 0.6186\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8603 - accuracy: 0.6884 - val_loss: 0.8647 - val_accuracy: 0.6254\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8039 - accuracy: 0.6955 - val_loss: 0.8401 - val_accuracy: 0.6369\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7709 - accuracy: 0.6991 - val_loss: 0.8141 - val_accuracy: 0.6504\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7525 - accuracy: 0.7041 - val_loss: 0.8287 - val_accuracy: 0.6254\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7322 - accuracy: 0.7096 - val_loss: 0.8041 - val_accuracy: 0.6439\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7148 - accuracy: 0.7150 - val_loss: 0.8236 - val_accuracy: 0.6315\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7004 - accuracy: 0.7188 - val_loss: 0.8250 - val_accuracy: 0.6318\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.6861 - accuracy: 0.7268 - val_loss: 0.8129 - val_accuracy: 0.6425\n",
      "5/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 54s 26ms/step - loss: 1.0957 - accuracy: 0.5847 - val_loss: 1.0845 - val_accuracy: 0.6035\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0890 - accuracy: 0.6163 - val_loss: 1.0607 - val_accuracy: 0.6036\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0665 - accuracy: 0.6160 - val_loss: 1.0157 - val_accuracy: 0.6140\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0514 - accuracy: 0.6062 - val_loss: 1.0201 - val_accuracy: 0.5985\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0465 - accuracy: 0.6008 - val_loss: 1.0164 - val_accuracy: 0.5981\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0413 - accuracy: 0.6009 - val_loss: 1.0095 - val_accuracy: 0.6001\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0349 - accuracy: 0.6060 - val_loss: 0.9999 - val_accuracy: 0.6068\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0267 - accuracy: 0.6138 - val_loss: 0.9873 - val_accuracy: 0.6182\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0157 - accuracy: 0.6249 - val_loss: 0.9705 - val_accuracy: 0.6322\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9999 - accuracy: 0.6434 - val_loss: 0.9462 - val_accuracy: 0.6578\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9698 - accuracy: 0.6847 - val_loss: 0.8779 - val_accuracy: 0.7319\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9125 - accuracy: 0.7545 - val_loss: 0.8069 - val_accuracy: 0.7711\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8855 - accuracy: 0.7650 - val_loss: 0.7827 - val_accuracy: 0.7750\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8662 - accuracy: 0.7666 - val_loss: 0.7647 - val_accuracy: 0.7722\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8505 - accuracy: 0.7653 - val_loss: 0.7507 - val_accuracy: 0.7699\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8372 - accuracy: 0.7615 - val_loss: 0.7398 - val_accuracy: 0.7690\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8260 - accuracy: 0.7571 - val_loss: 0.7313 - val_accuracy: 0.7651\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8162 - accuracy: 0.7517 - val_loss: 0.7251 - val_accuracy: 0.7600\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8078 - accuracy: 0.7464 - val_loss: 0.7207 - val_accuracy: 0.7546\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8003 - accuracy: 0.7428 - val_loss: 0.7167 - val_accuracy: 0.7486\n",
      "6/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 63s 31ms/step - loss: 0.7387 - accuracy: 0.7155 - val_loss: 0.5711 - val_accuracy: 0.7649\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.5907 - accuracy: 0.7786 - val_loss: 0.5175 - val_accuracy: 0.7960\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.5143 - accuracy: 0.8107 - val_loss: 0.5475 - val_accuracy: 0.7897\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.4408 - accuracy: 0.8342 - val_loss: 0.5678 - val_accuracy: 0.7897\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.3657 - accuracy: 0.8603 - val_loss: 0.6014 - val_accuracy: 0.7890\n",
      "7/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 51s 24ms/step - loss: 1.0954 - accuracy: 0.4349 - val_loss: 1.0860 - val_accuracy: 0.4636\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0675 - accuracy: 0.5520 - val_loss: 1.0394 - val_accuracy: 0.5644\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0506 - accuracy: 0.5739 - val_loss: 1.0206 - val_accuracy: 0.5746\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0209 - accuracy: 0.6050 - val_loss: 0.9275 - val_accuracy: 0.6086\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9332 - accuracy: 0.6576 - val_loss: 0.8605 - val_accuracy: 0.6279\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8545 - accuracy: 0.6942 - val_loss: 0.7520 - val_accuracy: 0.7049\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8021 - accuracy: 0.7012 - val_loss: 0.7003 - val_accuracy: 0.7138\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7705 - accuracy: 0.7035 - val_loss: 0.6729 - val_accuracy: 0.7167\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7490 - accuracy: 0.7078 - val_loss: 0.6577 - val_accuracy: 0.7192\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7319 - accuracy: 0.7120 - val_loss: 0.6467 - val_accuracy: 0.7194\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7183 - accuracy: 0.7161 - val_loss: 0.6383 - val_accuracy: 0.7221\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7033 - accuracy: 0.7197 - val_loss: 0.6228 - val_accuracy: 0.7268\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6901 - accuracy: 0.7241 - val_loss: 0.6144 - val_accuracy: 0.7321\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6776 - accuracy: 0.7292 - val_loss: 0.6041 - val_accuracy: 0.7351\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6650 - accuracy: 0.7359 - val_loss: 0.5951 - val_accuracy: 0.7386\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6539 - accuracy: 0.7429 - val_loss: 0.5847 - val_accuracy: 0.7481\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6431 - accuracy: 0.7487 - val_loss: 0.5768 - val_accuracy: 0.7525\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6352 - accuracy: 0.7523 - val_loss: 0.5763 - val_accuracy: 0.7558\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6281 - accuracy: 0.7565 - val_loss: 0.5741 - val_accuracy: 0.7578\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6174 - accuracy: 0.7607 - val_loss: 0.5800 - val_accuracy: 0.7551\n",
      "8/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 55s 26ms/step - loss: 1.0977 - accuracy: 0.5939 - val_loss: 1.0896 - val_accuracy: 0.6158\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0956 - accuracy: 0.6256 - val_loss: 1.0860 - val_accuracy: 0.6181\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0928 - accuracy: 0.6332 - val_loss: 1.0795 - val_accuracy: 0.6142\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0844 - accuracy: 0.6143 - val_loss: 1.0409 - val_accuracy: 0.6212\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0593 - accuracy: 0.6176 - val_loss: 1.0354 - val_accuracy: 0.6071\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0528 - accuracy: 0.6038 - val_loss: 1.0297 - val_accuracy: 0.5969\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0483 - accuracy: 0.5993 - val_loss: 1.0225 - val_accuracy: 0.5939\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0432 - accuracy: 0.5984 - val_loss: 1.0141 - val_accuracy: 0.5954\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0368 - accuracy: 0.6007 - val_loss: 1.0034 - val_accuracy: 0.6001\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0280 - accuracy: 0.6062 - val_loss: 0.9882 - val_accuracy: 0.6092\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0140 - accuracy: 0.6169 - val_loss: 0.9621 - val_accuracy: 0.6254\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9778 - accuracy: 0.6575 - val_loss: 0.8876 - val_accuracy: 0.7139\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9065 - accuracy: 0.7466 - val_loss: 0.8237 - val_accuracy: 0.7435\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8762 - accuracy: 0.7547 - val_loss: 0.7924 - val_accuracy: 0.7474\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8568 - accuracy: 0.7541 - val_loss: 0.7766 - val_accuracy: 0.7425\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8419 - accuracy: 0.7522 - val_loss: 0.7662 - val_accuracy: 0.7376\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8297 - accuracy: 0.7489 - val_loss: 0.7581 - val_accuracy: 0.7344\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8192 - accuracy: 0.7463 - val_loss: 0.7512 - val_accuracy: 0.7312\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8100 - accuracy: 0.7438 - val_loss: 0.7449 - val_accuracy: 0.7286\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8018 - accuracy: 0.7420 - val_loss: 0.7390 - val_accuracy: 0.7279\n",
      "9/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 66s 32ms/step - loss: 0.7355 - accuracy: 0.7217 - val_loss: 0.5474 - val_accuracy: 0.7768\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.5743 - accuracy: 0.7833 - val_loss: 0.6104 - val_accuracy: 0.7507\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.4693 - accuracy: 0.8230 - val_loss: 0.5820 - val_accuracy: 0.7701\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.3886 - accuracy: 0.8517 - val_loss: 0.6044 - val_accuracy: 0.7721\n",
      "10/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 52s 25ms/step - loss: 1.0794 - accuracy: 0.4656 - val_loss: 1.0354 - val_accuracy: 0.5565\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0380 - accuracy: 0.5887 - val_loss: 0.9901 - val_accuracy: 0.5969\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9581 - accuracy: 0.6593 - val_loss: 0.7938 - val_accuracy: 0.7431\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8621 - accuracy: 0.6985 - val_loss: 0.7197 - val_accuracy: 0.7485\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8076 - accuracy: 0.7019 - val_loss: 0.6722 - val_accuracy: 0.7407\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7742 - accuracy: 0.7056 - val_loss: 0.6853 - val_accuracy: 0.7135\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7516 - accuracy: 0.7097 - val_loss: 0.7077 - val_accuracy: 0.6928\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7310 - accuracy: 0.7165 - val_loss: 0.7004 - val_accuracy: 0.6847\n",
      "11/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 53s 25ms/step - loss: 1.0963 - accuracy: 0.6054 - val_loss: 1.0815 - val_accuracy: 0.6336\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0919 - accuracy: 0.6182 - val_loss: 1.0706 - val_accuracy: 0.6297\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0812 - accuracy: 0.6065 - val_loss: 1.0399 - val_accuracy: 0.6135\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0613 - accuracy: 0.6146 - val_loss: 1.0218 - val_accuracy: 0.6190\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0514 - accuracy: 0.6137 - val_loss: 1.0202 - val_accuracy: 0.6137\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0461 - accuracy: 0.6123 - val_loss: 1.0160 - val_accuracy: 0.6126\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0410 - accuracy: 0.6136 - val_loss: 1.0097 - val_accuracy: 0.6154\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0352 - accuracy: 0.6175 - val_loss: 1.0014 - val_accuracy: 0.6214\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0283 - accuracy: 0.6239 - val_loss: 0.9912 - val_accuracy: 0.6306\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 1.0196 - accuracy: 0.6330 - val_loss: 0.9784 - val_accuracy: 0.6403\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0080 - accuracy: 0.6462 - val_loss: 0.9625 - val_accuracy: 0.6562\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.9901 - accuracy: 0.6671 - val_loss: 0.9381 - val_accuracy: 0.6908\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.9530 - accuracy: 0.7217 - val_loss: 0.8825 - val_accuracy: 0.7465\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9208 - accuracy: 0.7567 - val_loss: 0.8436 - val_accuracy: 0.7621\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9013 - accuracy: 0.7661 - val_loss: 0.8182 - val_accuracy: 0.7694\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8854 - accuracy: 0.7710 - val_loss: 0.7988 - val_accuracy: 0.7728\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8718 - accuracy: 0.7741 - val_loss: 0.7830 - val_accuracy: 0.7725\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.8598 - accuracy: 0.7754 - val_loss: 0.7704 - val_accuracy: 0.7726\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 54s 27ms/step - loss: 0.8491 - accuracy: 0.7760 - val_loss: 0.7583 - val_accuracy: 0.7725\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8396 - accuracy: 0.7761 - val_loss: 0.7486 - val_accuracy: 0.7728\n",
      "12/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 71s 34ms/step - loss: 0.7295 - accuracy: 0.7171 - val_loss: 0.7024 - val_accuracy: 0.6833\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.5754 - accuracy: 0.7856 - val_loss: 0.6856 - val_accuracy: 0.7069\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.4677 - accuracy: 0.8257 - val_loss: 0.7374 - val_accuracy: 0.6786\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.3707 - accuracy: 0.8626 - val_loss: 0.6649 - val_accuracy: 0.7536\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 44s 21ms/step - loss: 0.3038 - accuracy: 0.8863 - val_loss: 0.6873 - val_accuracy: 0.7650\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.2549 - accuracy: 0.9049 - val_loss: 0.8015 - val_accuracy: 0.7306\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.2110 - accuracy: 0.9212 - val_loss: 0.9231 - val_accuracy: 0.6963\n",
      "13/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 55s 26ms/step - loss: 1.0904 - accuracy: 0.4470 - val_loss: 1.0578 - val_accuracy: 0.5854\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0500 - accuracy: 0.5839 - val_loss: 1.0287 - val_accuracy: 0.5865\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0005 - accuracy: 0.6290 - val_loss: 0.8889 - val_accuracy: 0.6672\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8935 - accuracy: 0.6804 - val_loss: 0.8297 - val_accuracy: 0.6601\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8257 - accuracy: 0.6971 - val_loss: 0.7626 - val_accuracy: 0.6715\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7845 - accuracy: 0.7060 - val_loss: 0.7336 - val_accuracy: 0.6851\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7545 - accuracy: 0.7142 - val_loss: 0.6922 - val_accuracy: 0.7007\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7338 - accuracy: 0.7200 - val_loss: 0.6301 - val_accuracy: 0.7419\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7177 - accuracy: 0.7219 - val_loss: 0.6221 - val_accuracy: 0.7425\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7018 - accuracy: 0.7276 - val_loss: 0.6069 - val_accuracy: 0.7487\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6868 - accuracy: 0.7325 - val_loss: 0.5915 - val_accuracy: 0.7557\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6719 - accuracy: 0.7389 - val_loss: 0.5783 - val_accuracy: 0.7665\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6585 - accuracy: 0.7453 - val_loss: 0.5921 - val_accuracy: 0.7538\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6477 - accuracy: 0.7509 - val_loss: 0.5664 - val_accuracy: 0.7724\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6377 - accuracy: 0.7543 - val_loss: 0.5544 - val_accuracy: 0.7769\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6295 - accuracy: 0.7569 - val_loss: 0.5387 - val_accuracy: 0.7858\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6194 - accuracy: 0.7613 - val_loss: 0.5370 - val_accuracy: 0.7833\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6306 - accuracy: 0.7583 - val_loss: 0.5361 - val_accuracy: 0.7878\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6066 - accuracy: 0.7686 - val_loss: 0.5275 - val_accuracy: 0.7854\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6003 - accuracy: 0.7698 - val_loss: 0.5205 - val_accuracy: 0.7901\n",
      "14/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 57s 27ms/step - loss: 1.0978 - accuracy: 0.4875 - val_loss: 1.0859 - val_accuracy: 0.6129\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0946 - accuracy: 0.6134 - val_loss: 1.0785 - val_accuracy: 0.6271\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0893 - accuracy: 0.6181 - val_loss: 1.0601 - val_accuracy: 0.6108\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0712 - accuracy: 0.6070 - val_loss: 1.0170 - val_accuracy: 0.6021\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0539 - accuracy: 0.5929 - val_loss: 1.0223 - val_accuracy: 0.5875\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0485 - accuracy: 0.5863 - val_loss: 1.0205 - val_accuracy: 0.5851\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0443 - accuracy: 0.5875 - val_loss: 1.0151 - val_accuracy: 0.5871\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0394 - accuracy: 0.5912 - val_loss: 1.0080 - val_accuracy: 0.5925\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0336 - accuracy: 0.5971 - val_loss: 0.9990 - val_accuracy: 0.6011\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0262 - accuracy: 0.6053 - val_loss: 0.9877 - val_accuracy: 0.6121\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0165 - accuracy: 0.6173 - val_loss: 0.9729 - val_accuracy: 0.6253\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0023 - accuracy: 0.6368 - val_loss: 0.9519 - val_accuracy: 0.6485\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9741 - accuracy: 0.6790 - val_loss: 0.8962 - val_accuracy: 0.7246\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 44s 21ms/step - loss: 0.9230 - accuracy: 0.7484 - val_loss: 0.8392 - val_accuracy: 0.7549\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8968 - accuracy: 0.7579 - val_loss: 0.8123 - val_accuracy: 0.7572\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8770 - accuracy: 0.7589 - val_loss: 0.7910 - val_accuracy: 0.7560\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8604 - accuracy: 0.7574 - val_loss: 0.7747 - val_accuracy: 0.7531\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8464 - accuracy: 0.7547 - val_loss: 0.7608 - val_accuracy: 0.7501\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8343 - accuracy: 0.7514 - val_loss: 0.7493 - val_accuracy: 0.7469\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8237 - accuracy: 0.7470 - val_loss: 0.7396 - val_accuracy: 0.7433\n",
      "15/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 70s 34ms/step - loss: 0.7389 - accuracy: 0.7209 - val_loss: 0.6012 - val_accuracy: 0.7435\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.5847 - accuracy: 0.7828 - val_loss: 0.5350 - val_accuracy: 0.7829\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.4945 - accuracy: 0.8184 - val_loss: 0.5325 - val_accuracy: 0.7971\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.3957 - accuracy: 0.8528 - val_loss: 0.5690 - val_accuracy: 0.8049\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.3209 - accuracy: 0.8806 - val_loss: 0.6061 - val_accuracy: 0.8115\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.2636 - accuracy: 0.9017 - val_loss: 0.6571 - val_accuracy: 0.8140\n",
      "16/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 56s 27ms/step - loss: 1.0807 - accuracy: 0.4767 - val_loss: 1.0409 - val_accuracy: 0.5533\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0501 - accuracy: 0.5783 - val_loss: 1.0179 - val_accuracy: 0.5742\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0136 - accuracy: 0.6178 - val_loss: 0.9035 - val_accuracy: 0.6742\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9099 - accuracy: 0.6698 - val_loss: 0.8165 - val_accuracy: 0.6751\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8377 - accuracy: 0.6977 - val_loss: 0.7414 - val_accuracy: 0.7050\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7927 - accuracy: 0.7087 - val_loss: 0.7066 - val_accuracy: 0.7025\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.7647 - accuracy: 0.7114 - val_loss: 0.6853 - val_accuracy: 0.7022\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7446 - accuracy: 0.7134 - val_loss: 0.6802 - val_accuracy: 0.6988\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7276 - accuracy: 0.7185 - val_loss: 0.6828 - val_accuracy: 0.6908\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7136 - accuracy: 0.7209 - val_loss: 0.6682 - val_accuracy: 0.6974\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7015 - accuracy: 0.7237 - val_loss: 0.6471 - val_accuracy: 0.7099\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6905 - accuracy: 0.7259 - val_loss: 0.6293 - val_accuracy: 0.7215\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6803 - accuracy: 0.7289 - val_loss: 0.6106 - val_accuracy: 0.7307\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6704 - accuracy: 0.7335 - val_loss: 0.6095 - val_accuracy: 0.7293\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6605 - accuracy: 0.7369 - val_loss: 0.6080 - val_accuracy: 0.7315\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6513 - accuracy: 0.7409 - val_loss: 0.6104 - val_accuracy: 0.7318\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6408 - accuracy: 0.7476 - val_loss: 0.6099 - val_accuracy: 0.7329\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6322 - accuracy: 0.7525 - val_loss: 0.6137 - val_accuracy: 0.7326\n",
      "17/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 59s 28ms/step - loss: 1.0973 - accuracy: 0.5325 - val_loss: 1.0878 - val_accuracy: 0.5978\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0942 - accuracy: 0.6210 - val_loss: 1.0824 - val_accuracy: 0.6068\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0904 - accuracy: 0.6181 - val_loss: 1.0744 - val_accuracy: 0.5843\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0820 - accuracy: 0.5892 - val_loss: 1.0438 - val_accuracy: 0.5699\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0579 - accuracy: 0.5971 - val_loss: 1.0242 - val_accuracy: 0.5828\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0482 - accuracy: 0.5863 - val_loss: 1.0248 - val_accuracy: 0.5775\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0433 - accuracy: 0.5853 - val_loss: 1.0178 - val_accuracy: 0.5796\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0372 - accuracy: 0.5900 - val_loss: 1.0081 - val_accuracy: 0.5881\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0288 - accuracy: 0.5991 - val_loss: 0.9947 - val_accuracy: 0.6006\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0160 - accuracy: 0.6145 - val_loss: 0.9738 - val_accuracy: 0.6229\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9876 - accuracy: 0.6563 - val_loss: 0.9065 - val_accuracy: 0.7222\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.9135 - accuracy: 0.7522 - val_loss: 0.8122 - val_accuracy: 0.7542\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8751 - accuracy: 0.7579 - val_loss: 0.7898 - val_accuracy: 0.7493\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8548 - accuracy: 0.7553 - val_loss: 0.7783 - val_accuracy: 0.7412\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8391 - accuracy: 0.7530 - val_loss: 0.7689 - val_accuracy: 0.7351\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 44s 21ms/step - loss: 0.8259 - accuracy: 0.7503 - val_loss: 0.7606 - val_accuracy: 0.7317\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8145 - accuracy: 0.7484 - val_loss: 0.7530 - val_accuracy: 0.7283\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8042 - accuracy: 0.7484 - val_loss: 0.7459 - val_accuracy: 0.7267\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.7949 - accuracy: 0.7487 - val_loss: 0.7393 - val_accuracy: 0.7276\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7862 - accuracy: 0.7492 - val_loss: 0.7335 - val_accuracy: 0.7275\n",
      "18/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 72s 35ms/step - loss: 0.7363 - accuracy: 0.7192 - val_loss: 0.6851 - val_accuracy: 0.6819\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.5523 - accuracy: 0.7930 - val_loss: 0.6521 - val_accuracy: 0.7188\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 47s 23ms/step - loss: 0.4314 - accuracy: 0.8433 - val_loss: 0.6268 - val_accuracy: 0.7524\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 47s 23ms/step - loss: 0.3593 - accuracy: 0.8689 - val_loss: 0.6857 - val_accuracy: 0.7468\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.3204 - accuracy: 0.8830 - val_loss: 0.6332 - val_accuracy: 0.7844\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.2360 - accuracy: 0.9139 - val_loss: 0.7448 - val_accuracy: 0.7718\n",
      "19/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 59s 28ms/step - loss: 1.0890 - accuracy: 0.5121 - val_loss: 1.0714 - val_accuracy: 0.3626\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0469 - accuracy: 0.5849 - val_loss: 1.0136 - val_accuracy: 0.5728\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9823 - accuracy: 0.6545 - val_loss: 0.8399 - val_accuracy: 0.7175\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8799 - accuracy: 0.6997 - val_loss: 0.7589 - val_accuracy: 0.7224\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8223 - accuracy: 0.7074 - val_loss: 0.7495 - val_accuracy: 0.6833\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.7838 - accuracy: 0.7082 - val_loss: 0.7568 - val_accuracy: 0.6508\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.7610 - accuracy: 0.7115 - val_loss: 0.8203 - val_accuracy: 0.6007\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.7399 - accuracy: 0.7168 - val_loss: 0.8193 - val_accuracy: 0.5885\n",
      "20/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 57s 28ms/step - loss: 1.0970 - accuracy: 0.6134 - val_loss: 1.0783 - val_accuracy: 0.6354\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0940 - accuracy: 0.6284 - val_loss: 1.0749 - val_accuracy: 0.6335\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0907 - accuracy: 0.6198 - val_loss: 1.0700 - val_accuracy: 0.6200\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0856 - accuracy: 0.5877 - val_loss: 1.0614 - val_accuracy: 0.5646\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0758 - accuracy: 0.5601 - val_loss: 1.0434 - val_accuracy: 0.5822\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0576 - accuracy: 0.6054 - val_loss: 1.0200 - val_accuracy: 0.6143\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0449 - accuracy: 0.6156 - val_loss: 1.0112 - val_accuracy: 0.6171\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0373 - accuracy: 0.6170 - val_loss: 1.0029 - val_accuracy: 0.6176\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0291 - accuracy: 0.6199 - val_loss: 0.9908 - val_accuracy: 0.6232\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0185 - accuracy: 0.6285 - val_loss: 0.9740 - val_accuracy: 0.6319\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0043 - accuracy: 0.6423 - val_loss: 0.9511 - val_accuracy: 0.6511\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9822 - accuracy: 0.6679 - val_loss: 0.9207 - val_accuracy: 0.6925\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9340 - accuracy: 0.7328 - val_loss: 0.8448 - val_accuracy: 0.7579\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8947 - accuracy: 0.7619 - val_loss: 0.8064 - val_accuracy: 0.7647\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8716 - accuracy: 0.7681 - val_loss: 0.7783 - val_accuracy: 0.7672\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8537 - accuracy: 0.7704 - val_loss: 0.7583 - val_accuracy: 0.7654\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8394 - accuracy: 0.7722 - val_loss: 0.7428 - val_accuracy: 0.7638\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8277 - accuracy: 0.7726 - val_loss: 0.7312 - val_accuracy: 0.7633\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8178 - accuracy: 0.7719 - val_loss: 0.7221 - val_accuracy: 0.7628\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 44s 21ms/step - loss: 0.8092 - accuracy: 0.7718 - val_loss: 0.7138 - val_accuracy: 0.7629\n",
      "21/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 74s 36ms/step - loss: 0.7311 - accuracy: 0.7223 - val_loss: 0.6030 - val_accuracy: 0.7383\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.5640 - accuracy: 0.7935 - val_loss: 0.5770 - val_accuracy: 0.7593\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.4311 - accuracy: 0.8401 - val_loss: 0.5959 - val_accuracy: 0.7758\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.3342 - accuracy: 0.8764 - val_loss: 0.6195 - val_accuracy: 0.7874\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.2734 - accuracy: 0.8980 - val_loss: 0.6591 - val_accuracy: 0.7865\n",
      "22/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 60s 29ms/step - loss: 1.0790 - accuracy: 0.5126 - val_loss: 1.0460 - val_accuracy: 0.5546\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0438 - accuracy: 0.5828 - val_loss: 1.0155 - val_accuracy: 0.5756\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9757 - accuracy: 0.6359 - val_loss: 0.9549 - val_accuracy: 0.5667\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8731 - accuracy: 0.6681 - val_loss: 0.8885 - val_accuracy: 0.5564\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8097 - accuracy: 0.6794 - val_loss: 0.7980 - val_accuracy: 0.6218\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.7720 - accuracy: 0.6921 - val_loss: 0.7497 - val_accuracy: 0.6514\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.7448 - accuracy: 0.7017 - val_loss: 0.7195 - val_accuracy: 0.6679\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.7230 - accuracy: 0.7086 - val_loss: 0.7060 - val_accuracy: 0.6699\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.7050 - accuracy: 0.7156 - val_loss: 0.6891 - val_accuracy: 0.6806\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.6882 - accuracy: 0.7222 - val_loss: 0.6639 - val_accuracy: 0.6971\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6747 - accuracy: 0.7298 - val_loss: 0.7037 - val_accuracy: 0.6831\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.6601 - accuracy: 0.7375 - val_loss: 0.6368 - val_accuracy: 0.7165\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.6499 - accuracy: 0.7407 - val_loss: 0.6279 - val_accuracy: 0.7311\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6370 - accuracy: 0.7476 - val_loss: 0.6300 - val_accuracy: 0.7343\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6272 - accuracy: 0.7552 - val_loss: 0.7082 - val_accuracy: 0.6867\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.6199 - accuracy: 0.7564 - val_loss: 0.6148 - val_accuracy: 0.7393\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6118 - accuracy: 0.7594 - val_loss: 0.6160 - val_accuracy: 0.7399\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6024 - accuracy: 0.7648 - val_loss: 0.6134 - val_accuracy: 0.7426\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.5982 - accuracy: 0.7631 - val_loss: 0.6059 - val_accuracy: 0.7425\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6011 - accuracy: 0.7647 - val_loss: 0.6047 - val_accuracy: 0.7469\n",
      "23/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 58s 28ms/step - loss: 1.0958 - accuracy: 0.5799 - val_loss: 1.0774 - val_accuracy: 0.6454\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0851 - accuracy: 0.6345 - val_loss: 1.0480 - val_accuracy: 0.6215\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0596 - accuracy: 0.6122 - val_loss: 1.0271 - val_accuracy: 0.6076\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0504 - accuracy: 0.6043 - val_loss: 1.0246 - val_accuracy: 0.6012\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0457 - accuracy: 0.6034 - val_loss: 1.0186 - val_accuracy: 0.6011\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0405 - accuracy: 0.6062 - val_loss: 1.0109 - val_accuracy: 0.6060\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0343 - accuracy: 0.6107 - val_loss: 1.0013 - val_accuracy: 0.6142\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0263 - accuracy: 0.6182 - val_loss: 0.9891 - val_accuracy: 0.6204\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0154 - accuracy: 0.6302 - val_loss: 0.9725 - val_accuracy: 0.6386\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9985 - accuracy: 0.6541 - val_loss: 0.9475 - val_accuracy: 0.6749\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9578 - accuracy: 0.7180 - val_loss: 0.8940 - val_accuracy: 0.7378\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9156 - accuracy: 0.7548 - val_loss: 0.8620 - val_accuracy: 0.7210\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8921 - accuracy: 0.7583 - val_loss: 0.8365 - val_accuracy: 0.7192\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8736 - accuracy: 0.7581 - val_loss: 0.8140 - val_accuracy: 0.7237\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8580 - accuracy: 0.7575 - val_loss: 0.7948 - val_accuracy: 0.7271\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8446 - accuracy: 0.7560 - val_loss: 0.7784 - val_accuracy: 0.7296\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8328 - accuracy: 0.7551 - val_loss: 0.7639 - val_accuracy: 0.7343\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8223 - accuracy: 0.7546 - val_loss: 0.7516 - val_accuracy: 0.7362\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8128 - accuracy: 0.7539 - val_loss: 0.7411 - val_accuracy: 0.7375\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8042 - accuracy: 0.7537 - val_loss: 0.7316 - val_accuracy: 0.7385\n",
      "24/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 72s 34ms/step - loss: 0.7374 - accuracy: 0.7221 - val_loss: 0.6035 - val_accuracy: 0.7493\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.5740 - accuracy: 0.7896 - val_loss: 0.6198 - val_accuracy: 0.7497\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.4506 - accuracy: 0.8327 - val_loss: 0.6045 - val_accuracy: 0.7656\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.3515 - accuracy: 0.8693 - val_loss: 0.6272 - val_accuracy: 0.7857\n",
      "25/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 59s 28ms/step - loss: 1.0768 - accuracy: 0.4876 - val_loss: 1.0219 - val_accuracy: 0.5900\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0407 - accuracy: 0.5899 - val_loss: 1.0024 - val_accuracy: 0.6178\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9606 - accuracy: 0.6569 - val_loss: 0.8547 - val_accuracy: 0.6768\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8631 - accuracy: 0.6882 - val_loss: 0.7034 - val_accuracy: 0.7624\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.8099 - accuracy: 0.7073 - val_loss: 0.8665 - val_accuracy: 0.6672\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7731 - accuracy: 0.7106 - val_loss: 0.7665 - val_accuracy: 0.6954\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7486 - accuracy: 0.7148 - val_loss: 0.7222 - val_accuracy: 0.7064\n",
      "26/27\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 58s 28ms/step - loss: 1.0948 - accuracy: 0.5604 - val_loss: 1.0794 - val_accuracy: 0.6139\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0868 - accuracy: 0.6065 - val_loss: 1.0553 - val_accuracy: 0.5808\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 1.0623 - accuracy: 0.5977 - val_loss: 1.0278 - val_accuracy: 0.5851\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0503 - accuracy: 0.5874 - val_loss: 1.0298 - val_accuracy: 0.5786\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0456 - accuracy: 0.5869 - val_loss: 1.0237 - val_accuracy: 0.5800\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0401 - accuracy: 0.5898 - val_loss: 1.0154 - val_accuracy: 0.5854\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0328 - accuracy: 0.5969 - val_loss: 1.0041 - val_accuracy: 0.5921\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0224 - accuracy: 0.6081 - val_loss: 0.9875 - val_accuracy: 0.6124\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0039 - accuracy: 0.6327 - val_loss: 0.9542 - val_accuracy: 0.6550\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9472 - accuracy: 0.7187 - val_loss: 0.8404 - val_accuracy: 0.7590\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8911 - accuracy: 0.7532 - val_loss: 0.7983 - val_accuracy: 0.7515\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8613 - accuracy: 0.7524 - val_loss: 0.7816 - val_accuracy: 0.7412\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.8425 - accuracy: 0.7502 - val_loss: 0.7731 - val_accuracy: 0.7344\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 48s 24ms/step - loss: 0.8277 - accuracy: 0.7476 - val_loss: 0.7650 - val_accuracy: 0.7282\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.8154 - accuracy: 0.7460 - val_loss: 0.7570 - val_accuracy: 0.7242\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 47s 23ms/step - loss: 0.8047 - accuracy: 0.7469 - val_loss: 0.7489 - val_accuracy: 0.7217\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.7953 - accuracy: 0.7475 - val_loss: 0.7413 - val_accuracy: 0.7214\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.7867 - accuracy: 0.7481 - val_loss: 0.7343 - val_accuracy: 0.7219\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 46s 23ms/step - loss: 0.7788 - accuracy: 0.7485 - val_loss: 0.7280 - val_accuracy: 0.7231\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.7714 - accuracy: 0.7494 - val_loss: 0.7224 - val_accuracy: 0.7240\n",
      "27/27\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "best_RNN, acc_RNN = grid_search_RNN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T11:38:45.258435800Z",
     "start_time": "2024-05-20T07:20:00.399695Z"
    }
   },
   "id": "9dc314cd24f69bae"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best val accuracy: 0.8140277862548828\n",
      "250/250 [==============================] - 3s 10ms/step - loss: 0.6555 - accuracy: 0.8076\n",
      "Test dataset accuracy: 0.8076249957084656\n",
      "250/250 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Best val accuracy: {acc_RNN}\")\n",
    "print(f\"Test dataset accuracy: {best_RNN.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(best_RNN)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T11:54:58.590308900Z",
     "start_time": "2024-05-20T11:54:53.892375600Z"
    }
   },
   "id": "908993389a27936e"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def grid_search_CNN(epochs=30, patience=3):\n",
    "    best_model = None\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for embedding_dim in param_grid_CNN['embedding_dim']:\n",
    "        for dropout_rate in param_grid_CNN['dropout_rate']:\n",
    "            for optimizer in param_grid_CNN['optimizer']:\n",
    "                for activation in param_grid_CNN['activation']:\n",
    "                    model = create_CNN(max_length=max_length,\n",
    "                                       embedding_dim=embedding_dim,\n",
    "                                       dropout_rate=dropout_rate,\n",
    "                                       optimizer=optimizer,\n",
    "                                       activation=activation)\n",
    "\n",
    "                    callbacks = [\n",
    "                        keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "                    ]\n",
    "\n",
    "                    history = model.fit(train_ds.cache(), epochs=epochs,\n",
    "                                        validation_data=val_ds.cache(),\n",
    "                                        callbacks=callbacks,\n",
    "                                        class_weight=class_weight)\n",
    "\n",
    "                    val_acc = history.history['val_accuracy'][-1]  # Get last validation accuracy\n",
    "                    if val_acc > best_accuracy:\n",
    "                        best_model = model\n",
    "                        best_accuracy = val_acc\n",
    "    return best_model, best_accuracy\n",
    "\n",
    "# Example usage (assuming you have prepared your train_data and val_data)\n",
    "\n",
    "# Example usage (assuming you have your training data)\n",
    "param_grid_CNN = {\n",
    "    'embedding_dim': [64, 128, 256],  \n",
    "    'dropout_rate': [0.2, 0.3, 0.5],  \n",
    "    'optimizer': ['adam', 'sgd'], \n",
    "    'activation': ['relu', 'leaky_relu']  \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T20:17:58.310390600Z",
     "start_time": "2024-05-19T20:17:58.303882700Z"
    }
   },
   "id": "203c7a48d4551f53"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8500 - accuracy: 0.6691 - val_loss: 0.6882 - val_accuracy: 0.7058\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6950 - accuracy: 0.7423 - val_loss: 0.6283 - val_accuracy: 0.7186\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6112 - accuracy: 0.7758 - val_loss: 0.5662 - val_accuracy: 0.7632\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5427 - accuracy: 0.8080 - val_loss: 0.6829 - val_accuracy: 0.7239\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4834 - accuracy: 0.8342 - val_loss: 0.7022 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4336 - accuracy: 0.8544 - val_loss: 0.6836 - val_accuracy: 0.7411\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 38s 18ms/step - loss: 0.8311 - accuracy: 0.6820 - val_loss: 0.6274 - val_accuracy: 0.7349\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6746 - accuracy: 0.7508 - val_loss: 0.5761 - val_accuracy: 0.7651\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5943 - accuracy: 0.7830 - val_loss: 0.5480 - val_accuracy: 0.7815\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5253 - accuracy: 0.8136 - val_loss: 0.5534 - val_accuracy: 0.7950\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.4668 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7914\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4174 - accuracy: 0.8582 - val_loss: 0.6288 - val_accuracy: 0.7664\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 26s 13ms/step - loss: 1.1270 - accuracy: 0.3303 - val_loss: 1.0604 - val_accuracy: 0.6396\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0916 - accuracy: 0.4311 - val_loss: 1.0246 - val_accuracy: 0.6275\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 1.0702 - accuracy: 0.5289 - val_loss: 1.0273 - val_accuracy: 0.6046\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0641 - accuracy: 0.5413 - val_loss: 1.0198 - val_accuracy: 0.6040\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 1.0623 - accuracy: 0.5518 - val_loss: 1.0177 - val_accuracy: 0.6039\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0603 - accuracy: 0.5536 - val_loss: 1.0180 - val_accuracy: 0.6028\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0598 - accuracy: 0.5531 - val_loss: 1.0131 - val_accuracy: 0.6064\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0579 - accuracy: 0.5608 - val_loss: 1.0144 - val_accuracy: 0.6087\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0470 - accuracy: 0.5772 - val_loss: 0.9640 - val_accuracy: 0.6529\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.9625 - accuracy: 0.6434 - val_loss: 0.8394 - val_accuracy: 0.7003\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.8892 - accuracy: 0.6816 - val_loss: 0.7508 - val_accuracy: 0.7329\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.8390 - accuracy: 0.7033 - val_loss: 0.6903 - val_accuracy: 0.7546\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7987 - accuracy: 0.7078 - val_loss: 0.6640 - val_accuracy: 0.7357\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7711 - accuracy: 0.7061 - val_loss: 0.6341 - val_accuracy: 0.7419\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7457 - accuracy: 0.7075 - val_loss: 0.6113 - val_accuracy: 0.7360\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7299 - accuracy: 0.7079 - val_loss: 0.6009 - val_accuracy: 0.7386\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7166 - accuracy: 0.7119 - val_loss: 0.5950 - val_accuracy: 0.7386\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7068 - accuracy: 0.7117 - val_loss: 0.5948 - val_accuracy: 0.7371\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6959 - accuracy: 0.7154 - val_loss: 0.5914 - val_accuracy: 0.7417\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6880 - accuracy: 0.7176 - val_loss: 0.5846 - val_accuracy: 0.7396\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6804 - accuracy: 0.7200 - val_loss: 0.5785 - val_accuracy: 0.7457\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6721 - accuracy: 0.7211 - val_loss: 0.5729 - val_accuracy: 0.7490\n",
      "Epoch 23/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6669 - accuracy: 0.7235 - val_loss: 0.5776 - val_accuracy: 0.7392\n",
      "Epoch 24/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6601 - accuracy: 0.7238 - val_loss: 0.5749 - val_accuracy: 0.7460\n",
      "Epoch 25/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6544 - accuracy: 0.7250 - val_loss: 0.5751 - val_accuracy: 0.7392\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 25s 12ms/step - loss: 1.1292 - accuracy: 0.3303 - val_loss: 1.1152 - val_accuracy: 0.0710\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1113 - accuracy: 0.3337 - val_loss: 1.1188 - val_accuracy: 0.0710\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0955 - accuracy: 0.3895 - val_loss: 1.0771 - val_accuracy: 0.4994\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0701 - accuracy: 0.5310 - val_loss: 1.0626 - val_accuracy: 0.5340\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0626 - accuracy: 0.5452 - val_loss: 1.0600 - val_accuracy: 0.5308\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0623 - accuracy: 0.5483 - val_loss: 1.0633 - val_accuracy: 0.5254\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0605 - accuracy: 0.5545 - val_loss: 1.0570 - val_accuracy: 0.5399\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0596 - accuracy: 0.5570 - val_loss: 1.0551 - val_accuracy: 0.5397\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0589 - accuracy: 0.5614 - val_loss: 1.0557 - val_accuracy: 0.5368\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0570 - accuracy: 0.5625 - val_loss: 1.0495 - val_accuracy: 0.5453\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0498 - accuracy: 0.5750 - val_loss: 1.0116 - val_accuracy: 0.5856\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.9777 - accuracy: 0.6331 - val_loss: 0.8544 - val_accuracy: 0.7022\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8949 - accuracy: 0.6772 - val_loss: 0.7538 - val_accuracy: 0.7344\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.8408 - accuracy: 0.6962 - val_loss: 0.7058 - val_accuracy: 0.7218\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7981 - accuracy: 0.7027 - val_loss: 0.6596 - val_accuracy: 0.7275\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7690 - accuracy: 0.7048 - val_loss: 0.6597 - val_accuracy: 0.7108\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7454 - accuracy: 0.7069 - val_loss: 0.6412 - val_accuracy: 0.7094\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7296 - accuracy: 0.7068 - val_loss: 0.6373 - val_accuracy: 0.7083\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7137 - accuracy: 0.7119 - val_loss: 0.6278 - val_accuracy: 0.7079\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7076 - accuracy: 0.7098 - val_loss: 0.6151 - val_accuracy: 0.7142\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6976 - accuracy: 0.7137 - val_loss: 0.6052 - val_accuracy: 0.7186\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6865 - accuracy: 0.7166 - val_loss: 0.6143 - val_accuracy: 0.7099\n",
      "Epoch 23/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6793 - accuracy: 0.7169 - val_loss: 0.6375 - val_accuracy: 0.6925\n",
      "Epoch 24/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6741 - accuracy: 0.7199 - val_loss: 0.6114 - val_accuracy: 0.7135\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8649 - accuracy: 0.6484 - val_loss: 0.6299 - val_accuracy: 0.7262\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6810 - accuracy: 0.7483 - val_loss: 0.5653 - val_accuracy: 0.7628\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5969 - accuracy: 0.7902 - val_loss: 0.5835 - val_accuracy: 0.7628\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5238 - accuracy: 0.8237 - val_loss: 0.5872 - val_accuracy: 0.7742\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4616 - accuracy: 0.8496 - val_loss: 0.5851 - val_accuracy: 0.7987\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 38s 18ms/step - loss: 0.8440 - accuracy: 0.6773 - val_loss: 0.6019 - val_accuracy: 0.7425\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7007 - accuracy: 0.7313 - val_loss: 0.5572 - val_accuracy: 0.7739\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6325 - accuracy: 0.7607 - val_loss: 0.5731 - val_accuracy: 0.7682\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5684 - accuracy: 0.7896 - val_loss: 0.6949 - val_accuracy: 0.7246\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.5173 - accuracy: 0.8146 - val_loss: 0.6386 - val_accuracy: 0.7700\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 26s 13ms/step - loss: 1.1313 - accuracy: 0.3432 - val_loss: 1.1477 - val_accuracy: 0.0710\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0980 - accuracy: 0.3894 - val_loss: 1.1013 - val_accuracy: 0.3492\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0700 - accuracy: 0.5274 - val_loss: 1.0776 - val_accuracy: 0.4787\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0637 - accuracy: 0.5445 - val_loss: 1.0758 - val_accuracy: 0.4888\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0630 - accuracy: 0.5484 - val_loss: 1.0750 - val_accuracy: 0.4860\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0621 - accuracy: 0.5473 - val_loss: 1.0760 - val_accuracy: 0.4811\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0610 - accuracy: 0.5551 - val_loss: 1.0706 - val_accuracy: 0.5043\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0611 - accuracy: 0.5573 - val_loss: 1.0668 - val_accuracy: 0.5049\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0593 - accuracy: 0.5605 - val_loss: 1.0611 - val_accuracy: 0.5204\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0565 - accuracy: 0.5700 - val_loss: 1.0462 - val_accuracy: 0.5406\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0349 - accuracy: 0.5903 - val_loss: 0.9481 - val_accuracy: 0.6114\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.9348 - accuracy: 0.6506 - val_loss: 0.8633 - val_accuracy: 0.6907\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8620 - accuracy: 0.6819 - val_loss: 0.7805 - val_accuracy: 0.6728\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8130 - accuracy: 0.6884 - val_loss: 0.7265 - val_accuracy: 0.6931\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7815 - accuracy: 0.6894 - val_loss: 0.6833 - val_accuracy: 0.6986\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7560 - accuracy: 0.6938 - val_loss: 0.6716 - val_accuracy: 0.6919\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7396 - accuracy: 0.6971 - val_loss: 0.6542 - val_accuracy: 0.6946\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7238 - accuracy: 0.7015 - val_loss: 0.6404 - val_accuracy: 0.7104\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7118 - accuracy: 0.7054 - val_loss: 0.6294 - val_accuracy: 0.7121\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7024 - accuracy: 0.7073 - val_loss: 0.6172 - val_accuracy: 0.7132\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6934 - accuracy: 0.7096 - val_loss: 0.6194 - val_accuracy: 0.7068\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6874 - accuracy: 0.7100 - val_loss: 0.6205 - val_accuracy: 0.7172\n",
      "Epoch 23/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6790 - accuracy: 0.7147 - val_loss: 0.6280 - val_accuracy: 0.7107\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 26s 13ms/step - loss: 1.1351 - accuracy: 0.3293 - val_loss: 1.1114 - val_accuracy: 0.0710\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 1.1096 - accuracy: 0.3276 - val_loss: 1.1070 - val_accuracy: 0.0710\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1015 - accuracy: 0.3396 - val_loss: 1.1007 - val_accuracy: 0.0710\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0866 - accuracy: 0.4413 - val_loss: 1.0541 - val_accuracy: 0.5739\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 18s 9ms/step - loss: 1.0674 - accuracy: 0.5516 - val_loss: 1.0513 - val_accuracy: 0.5685\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0642 - accuracy: 0.5538 - val_loss: 1.0486 - val_accuracy: 0.5507\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0624 - accuracy: 0.5515 - val_loss: 1.0466 - val_accuracy: 0.5579\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0618 - accuracy: 0.5557 - val_loss: 1.0394 - val_accuracy: 0.5606\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 1.0605 - accuracy: 0.5570 - val_loss: 1.0411 - val_accuracy: 0.5650\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0603 - accuracy: 0.5646 - val_loss: 1.0418 - val_accuracy: 0.5679\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0578 - accuracy: 0.5708 - val_loss: 1.0315 - val_accuracy: 0.5833\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0519 - accuracy: 0.5756 - val_loss: 1.0118 - val_accuracy: 0.5939\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.9850 - accuracy: 0.6199 - val_loss: 0.9099 - val_accuracy: 0.6419\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8927 - accuracy: 0.6720 - val_loss: 1.0952 - val_accuracy: 0.4404\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8383 - accuracy: 0.6876 - val_loss: 0.9321 - val_accuracy: 0.5429\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 0.7999 - accuracy: 0.6871 - val_loss: 0.8887 - val_accuracy: 0.5586\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7750 - accuracy: 0.6898 - val_loss: 0.7777 - val_accuracy: 0.6175\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7526 - accuracy: 0.6940 - val_loss: 0.8073 - val_accuracy: 0.5982\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7345 - accuracy: 0.6991 - val_loss: 0.7379 - val_accuracy: 0.6317\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7240 - accuracy: 0.7024 - val_loss: 0.7881 - val_accuracy: 0.6022\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7148 - accuracy: 0.7034 - val_loss: 0.7480 - val_accuracy: 0.6176\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7059 - accuracy: 0.7063 - val_loss: 0.7863 - val_accuracy: 0.5971\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 40s 19ms/step - loss: 0.9075 - accuracy: 0.6477 - val_loss: 0.7045 - val_accuracy: 0.7644\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7340 - accuracy: 0.7492 - val_loss: 0.6164 - val_accuracy: 0.7778\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6671 - accuracy: 0.7770 - val_loss: 0.6112 - val_accuracy: 0.7657\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6024 - accuracy: 0.8061 - val_loss: 0.6057 - val_accuracy: 0.7833\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5455 - accuracy: 0.8310 - val_loss: 0.6791 - val_accuracy: 0.7825\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.4904 - accuracy: 0.8546 - val_loss: 0.6456 - val_accuracy: 0.7785\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.4452 - accuracy: 0.8723 - val_loss: 0.6225 - val_accuracy: 0.8012\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 40s 19ms/step - loss: 1.0078 - accuracy: 0.4419 - val_loss: 0.6959 - val_accuracy: 0.7392\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7869 - accuracy: 0.6976 - val_loss: 0.6224 - val_accuracy: 0.7429\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7339 - accuracy: 0.7091 - val_loss: 0.6229 - val_accuracy: 0.7356\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6921 - accuracy: 0.7219 - val_loss: 0.6161 - val_accuracy: 0.7126\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6520 - accuracy: 0.7371 - val_loss: 0.6190 - val_accuracy: 0.7401\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6137 - accuracy: 0.7567 - val_loss: 0.5896 - val_accuracy: 0.7614\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.5663 - accuracy: 0.7785 - val_loss: 0.5996 - val_accuracy: 0.7539\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.5285 - accuracy: 0.7990 - val_loss: 0.5915 - val_accuracy: 0.7893\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4931 - accuracy: 0.8158 - val_loss: 0.6377 - val_accuracy: 0.7622\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 27s 13ms/step - loss: 1.1469 - accuracy: 0.3280 - val_loss: 1.0824 - val_accuracy: 0.6624\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1031 - accuracy: 0.3217 - val_loss: 1.0892 - val_accuracy: 0.6624\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1012 - accuracy: 0.3218 - val_loss: 1.0874 - val_accuracy: 0.6624\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1007 - accuracy: 0.3269 - val_loss: 1.0842 - val_accuracy: 0.6624\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 27s 13ms/step - loss: 1.1450 - accuracy: 0.3352 - val_loss: 1.0640 - val_accuracy: 0.6624\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1035 - accuracy: 0.3249 - val_loss: 1.0649 - val_accuracy: 0.6624\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1011 - accuracy: 0.3204 - val_loss: 1.0630 - val_accuracy: 0.6624\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1000 - accuracy: 0.3297 - val_loss: 1.0588 - val_accuracy: 0.6526\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 1.0908 - accuracy: 0.4271 - val_loss: 1.0184 - val_accuracy: 0.6335\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0712 - accuracy: 0.5472 - val_loss: 1.0169 - val_accuracy: 0.6237\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0666 - accuracy: 0.5502 - val_loss: 1.0151 - val_accuracy: 0.6144\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0651 - accuracy: 0.5517 - val_loss: 1.0067 - val_accuracy: 0.6160\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0639 - accuracy: 0.5481 - val_loss: 1.0234 - val_accuracy: 0.6092\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0637 - accuracy: 0.5575 - val_loss: 1.0230 - val_accuracy: 0.6115\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0629 - accuracy: 0.5630 - val_loss: 1.0196 - val_accuracy: 0.6169\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "best_CNN, acc_CNN = grid_search_CNN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T20:58:54.753670600Z",
     "start_time": "2024-05-19T20:17:58.310390600Z"
    }
   },
   "id": "8410bf9ad050c5f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7756d6ea51741a37"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, 100, 128)          1024000   \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 96, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 48, 128)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 48, 64)            32832     \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 24, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 24, 32)            8224      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 12, 32)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 12, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 6, 32)             0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 6, 10)             330       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 10)             0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 183       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1151745 (4.39 MB)\n",
      "Trainable params: 1151745 (4.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1419/2025 [====================>.........] - ETA: 9s - loss: 0.8580 - accuracy: 0.6433"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Train the model (replace with your training and validation data)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      6\u001B[0m     keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.002\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[1;32m      7\u001B[0m ]\n\u001B[0;32m----> 9\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39mevaluate(test_ds)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest dataset accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mevaluate(test_ds)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = create_CNN(max_length)\n",
    "model.summary()\n",
    "\n",
    "# Train the model (replace with your training and validation data)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.002, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds.cache(), epochs=3, validation_data=val_ds.cache(), callbacks=callbacks)\n",
    "model.evaluate(test_ds)\n",
    "print(f\"Test dataset accuracy: {model.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:45:02.978788Z",
     "start_time": "2024-05-19T18:44:40.859714300Z"
    }
   },
   "id": "5aaa5fc4ba9bc7ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
