{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Text classification (sentiment analysis)\n",
    "Task: Predict sentiment of Amazon reviews\n",
    "Dataset: Beans from TFDS"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbbc77f284814682"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f0474e0967c03828"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Loading dataset & basic preprocessing\n",
    "- removal of reviews shorter than 5 characters\n",
    "- mapping from 1-5 -> 0,1,2\n",
    "- subsampling - without replacement, random state 42, 80 000 rows"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ee5b5a6106d6686"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:00.558295800Z",
     "start_time": "2024-05-19T18:18:58.310112500Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:18:59.424529: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-19 20:18:59.424590: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-19 20:18:59.426082: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-19 20:18:59.436999: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-19 20:19:00.050185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from IPython.display import display\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import datetime\n",
    "from keras_tuner import HyperModel, RandomSearch\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.15.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:00.564394700Z",
     "start_time": "2024-05-19T18:19:00.562395200Z"
    }
   },
   "id": "ca34945a70395e1f"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:19:00.789756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:00.820382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:00.820438: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:00.830030600Z",
     "start_time": "2024-05-19T18:19:00.613153300Z"
    }
   },
   "id": "4dd962ce90049d5a"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/amazon_reviews_us_Major_Appliances_v1_00.tsv', sep='\\t', on_bad_lines='skip')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:01.594894600Z",
     "start_time": "2024-05-19T18:19:00.825521100Z"
    }
   },
   "id": "41ff8b299de307d2"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "(96834, 15)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:01.594894600Z",
     "start_time": "2024-05-19T18:19:01.591894800Z"
    }
   },
   "id": "c630cd8ed64d4f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# remove nas and duplicate reviews\n",
    "df.dropna(axis=0, subset=['review_body'], inplace=True)\n",
    "df.drop_duplicates(subset=['review_body'], inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:01.655815800Z",
     "start_time": "2024-05-19T18:19:01.639226100Z"
    }
   },
   "id": "861e0cae068fbc6"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "(93446, 15)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:01.656816400Z",
     "start_time": "2024-05-19T18:19:01.651299800Z"
    }
   },
   "id": "4761880489557793"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/balv05/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopword_list = nltk.corpus.stopwords.words(\"english\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:01.744822700Z",
     "start_time": "2024-05-19T18:19:01.654812500Z"
    }
   },
   "id": "296446ff70a87882"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def remove_tags(review):\n",
    "    return re.sub(pattern='<.*?>', string=review , repl=' ') \n",
    "\n",
    "def keep_alnum(review):\n",
    "    return re.sub(pattern='[^A-Za-z\\d\\s:]', string=review, repl=' ')\n",
    "\n",
    "def strip_spaces(review):\n",
    "    return re.sub(pattern='[\\s]{2,}', string=review, repl=' ')\n",
    "\n",
    "def lowercase(review):\n",
    "    return review.lower()\n",
    "\n",
    "def remove_stopwords(review):\n",
    "    review_list = review.split()\n",
    "    return \" \".join([word for word in review_list if word not in stopword_list])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:01.744822700Z",
     "start_time": "2024-05-19T18:19:01.742392500Z"
    }
   },
   "id": "feccec45640d371c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "df['review_body'] = df['review_body'].apply(remove_tags)        # remove html tags\n",
    "df['review_body'] = df['review_body'].apply(keep_alnum)         # remove sub unicode char\n",
    "df['review_body'] = df['review_body'].apply(strip_spaces)       # strip all unnecessary whitespaces\n",
    "df['review_body'] = df['review_body'].apply(lowercase)          # put everything into lowercase\n",
    "df['review_body'] = df['review_body'].apply(remove_stopwords)   # put everything into lowercase\n",
    "df = df[df['review_body'].str.len() > 5]                        # keep only reviews longer than 5 characters"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.858820600Z",
     "start_time": "2024-05-19T18:19:01.745825400Z"
    }
   },
   "id": "ab4b0c058041911e"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "      marketplace  customer_id       review_id  product_id  product_parent  \\\n0              US     16199106  R203HPW78Z7N4K  B0067WNSZY       633038551   \n1              US     16374060  R2EAIGVLEALSP3  B002QSXK60       811766671   \n2              US     15322085  R1K1CD73HHLILA  B00EC452R6       345562728   \n3              US     32004835  R2KZBMOFRMYOPO  B00MVVIF2G       563052763   \n4              US     25414497   R6BIZOZY6UD01  B00IY7BNUW       874236579   \n...           ...          ...             ...         ...             ...   \n96829          US     37431087  R3CYIDM3UEY5PA  B00005O64S       222987122   \n96830          US     44686434  R1PLFLGSA6N9WU  B00005O64T       802734810   \n96831          US     36739731   RBPARLMOY6ZU5  B00005O64S       222987122   \n96832          US     50744080   RSS5TDZOGUEB6  B00004SACT       344802997   \n96833          US     48699462  R1X5L2BT3H084O  B00004SACT       344802997   \n\n                                           product_title  product_category  \\\n0      FGGF3032MW Gallery Series 30\" Wide Freestandin...  Major Appliances   \n1                              Best Hand Clothes Wringer  Major Appliances   \n2                        Supco SET184 Thermal Cutoff Kit  Major Appliances   \n3      Midea WHS-160RB1 Compact Single Reversible Doo...  Major Appliances   \n4                          Avalon Bay Portable Ice Maker  Major Appliances   \n...                                                  ...               ...   \n96829  Haier HDT18PA Space Saver Compact Countertop D...  Major Appliances   \n96830  Haier America HSE02-WNAWW 1.8-Cubic-Foot Capac...  Major Appliances   \n96831  Haier HDT18PA Space Saver Compact Countertop D...  Major Appliances   \n96832         Sanyo Two-Door 2.9 Cubic Foot Refrigerator  Major Appliances   \n96833         Sanyo Two-Door 2.9 Cubic Foot Refrigerator  Major Appliances   \n\n       star_rating  helpful_votes  total_votes vine verified_purchase  \\\n0                5              0            0    N                 Y   \n1                5              1            1    N                 Y   \n2                5              0            0    N                 Y   \n3                5              1            1    N                 Y   \n4                5              0            0    N                 Y   \n...            ...            ...          ...  ...               ...   \n96829            4             37           43    N                 N   \n96830            1             33           39    N                 N   \n96831            5              6           45    N                 N   \n96832            4             71           71    N                 N   \n96833            3              8           40    N                 N   \n\n                                  review_headline  \\\n0      If you need a new stove, this is a winner.   \n1                                      Five Stars   \n2                                   Fast Shipping   \n3                                      Five Stars   \n4                                      Five Stars   \n...                                           ...   \n96829  Pretty good dishwasher for small apartment   \n96830                          Does not last long   \n96831                 Rave review for space saver   \n96832                  Sanyo compact refrigerator   \n96833                               a normal frig   \n\n                                             review_body review_date  \n0      great stove wonderful replacement sort antique...  2015-08-31  \n1                                           worked great  2015-08-31  \n2                   part exactly needed saved purchasing  2015-08-31  \n3      love refrigerator keeps everything cold recommend  2015-08-31  \n4                      running store ice works perfectly  2015-08-31  \n...                                                  ...         ...  \n96829  pretty good dishwasher price good job cleaning...  2002-07-14  \n96830  bought office extremely dissatisfied stopped w...  2002-06-03  \n96831  saw small dishwasher thought wonderful idea sm...  2002-05-05  \n96832  probably best small refrigerator market true f...  2000-09-29  \n96833  normal mid sized refrigerater good price reall...  2000-08-26  \n\n[92899 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>marketplace</th>\n      <th>customer_id</th>\n      <th>review_id</th>\n      <th>product_id</th>\n      <th>product_parent</th>\n      <th>product_title</th>\n      <th>product_category</th>\n      <th>star_rating</th>\n      <th>helpful_votes</th>\n      <th>total_votes</th>\n      <th>vine</th>\n      <th>verified_purchase</th>\n      <th>review_headline</th>\n      <th>review_body</th>\n      <th>review_date</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>US</td>\n      <td>16199106</td>\n      <td>R203HPW78Z7N4K</td>\n      <td>B0067WNSZY</td>\n      <td>633038551</td>\n      <td>FGGF3032MW Gallery Series 30\" Wide Freestandin...</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>If you need a new stove, this is a winner.</td>\n      <td>great stove wonderful replacement sort antique...</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>US</td>\n      <td>16374060</td>\n      <td>R2EAIGVLEALSP3</td>\n      <td>B002QSXK60</td>\n      <td>811766671</td>\n      <td>Best Hand Clothes Wringer</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Five Stars</td>\n      <td>worked great</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>US</td>\n      <td>15322085</td>\n      <td>R1K1CD73HHLILA</td>\n      <td>B00EC452R6</td>\n      <td>345562728</td>\n      <td>Supco SET184 Thermal Cutoff Kit</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Fast Shipping</td>\n      <td>part exactly needed saved purchasing</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>US</td>\n      <td>32004835</td>\n      <td>R2KZBMOFRMYOPO</td>\n      <td>B00MVVIF2G</td>\n      <td>563052763</td>\n      <td>Midea WHS-160RB1 Compact Single Reversible Doo...</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Five Stars</td>\n      <td>love refrigerator keeps everything cold recommend</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>US</td>\n      <td>25414497</td>\n      <td>R6BIZOZY6UD01</td>\n      <td>B00IY7BNUW</td>\n      <td>874236579</td>\n      <td>Avalon Bay Portable Ice Maker</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Five Stars</td>\n      <td>running store ice works perfectly</td>\n      <td>2015-08-31</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>96829</th>\n      <td>US</td>\n      <td>37431087</td>\n      <td>R3CYIDM3UEY5PA</td>\n      <td>B00005O64S</td>\n      <td>222987122</td>\n      <td>Haier HDT18PA Space Saver Compact Countertop D...</td>\n      <td>Major Appliances</td>\n      <td>4</td>\n      <td>37</td>\n      <td>43</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Pretty good dishwasher for small apartment</td>\n      <td>pretty good dishwasher price good job cleaning...</td>\n      <td>2002-07-14</td>\n    </tr>\n    <tr>\n      <th>96830</th>\n      <td>US</td>\n      <td>44686434</td>\n      <td>R1PLFLGSA6N9WU</td>\n      <td>B00005O64T</td>\n      <td>802734810</td>\n      <td>Haier America HSE02-WNAWW 1.8-Cubic-Foot Capac...</td>\n      <td>Major Appliances</td>\n      <td>1</td>\n      <td>33</td>\n      <td>39</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Does not last long</td>\n      <td>bought office extremely dissatisfied stopped w...</td>\n      <td>2002-06-03</td>\n    </tr>\n    <tr>\n      <th>96831</th>\n      <td>US</td>\n      <td>36739731</td>\n      <td>RBPARLMOY6ZU5</td>\n      <td>B00005O64S</td>\n      <td>222987122</td>\n      <td>Haier HDT18PA Space Saver Compact Countertop D...</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>6</td>\n      <td>45</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Rave review for space saver</td>\n      <td>saw small dishwasher thought wonderful idea sm...</td>\n      <td>2002-05-05</td>\n    </tr>\n    <tr>\n      <th>96832</th>\n      <td>US</td>\n      <td>50744080</td>\n      <td>RSS5TDZOGUEB6</td>\n      <td>B00004SACT</td>\n      <td>344802997</td>\n      <td>Sanyo Two-Door 2.9 Cubic Foot Refrigerator</td>\n      <td>Major Appliances</td>\n      <td>4</td>\n      <td>71</td>\n      <td>71</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Sanyo compact refrigerator</td>\n      <td>probably best small refrigerator market true f...</td>\n      <td>2000-09-29</td>\n    </tr>\n    <tr>\n      <th>96833</th>\n      <td>US</td>\n      <td>48699462</td>\n      <td>R1X5L2BT3H084O</td>\n      <td>B00004SACT</td>\n      <td>344802997</td>\n      <td>Sanyo Two-Door 2.9 Cubic Foot Refrigerator</td>\n      <td>Major Appliances</td>\n      <td>3</td>\n      <td>8</td>\n      <td>40</td>\n      <td>N</td>\n      <td>N</td>\n      <td>a normal frig</td>\n      <td>normal mid sized refrigerater good price reall...</td>\n      <td>2000-08-26</td>\n    </tr>\n  </tbody>\n</table>\n<p>92899 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.871982Z",
     "start_time": "2024-05-19T18:19:07.864432600Z"
    }
   },
   "id": "633603daaf3937ff"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "df.loc[df['star_rating'] < 3, 'sentiment'] = 0\n",
    "df.loc[df['star_rating'] == 3, 'sentiment'] = 1\n",
    "df.loc[df['star_rating'] > 3, 'sentiment'] = 2\n",
    "df['sentiment'] = df['sentiment'].astype('int')\n",
    "df.drop('star_rating', axis=1, inplace=True)\n",
    "df = resample(df, n_samples=80000, random_state=42, replace=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.954781500Z",
     "start_time": "2024-05-19T18:19:07.870985900Z"
    }
   },
   "id": "174a2be074f5703"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "      marketplace  customer_id       review_id  product_id  product_parent  \\\n71963          US     23022807  R3IZQ5QBR0C7B7  B0039V7JFG       184993957   \n15508          US     21831333  R2LGGHUB944XMT  B00EJPHJVK       516641616   \n3110           US     11941986  R21U3YZPS3MBXG  B00HH2YZT6        73366442   \n88804          US     46476694  R2JZ0YSJ5QEZX4  B001VKY8GU       232040651   \n18295          US     48338607  R2QENB1J5LBM14  B00MZH0OPC       394118467   \n...           ...          ...             ...         ...             ...   \n62973          US     31634986  R173X6QPB1N8SY  B004HXDLJ8       693470227   \n45682          US     52949439   R4YB9KY26NLPP  B003GFAY52       647457047   \n84940          US     42829199  R1W9QEUT7MIYGD  B004WP4BAO       480751909   \n1873           US     19293947  R12LFU2ZVPAZSS  B0125S2K0M       504103070   \n53872          US     11233134  R2S04Z77YZXZAP  B007VXJ0HS       285649250   \n\n                                           product_title  product_category  \\\n71963            LG 3.6 CF FRONT LOAD WASHER DRYER COMBO  Major Appliances   \n15508  Fantech Lint Trap for Dryer Booster - DBLT4W (...  Major Appliances   \n3110   Samsung RF32FMQDBSR 4-Door Refrigerator with C...  Major Appliances   \n88804           Koolatron Coca Cola Personal Cube Fridge  Major Appliances   \n18295  ( 2 PACK ) 3392519 - DRYER THERMAL FUSE for Wh...  Major Appliances   \n...                                                  ...               ...   \n62973  Whynter BWR-18SD 18 Bottle Built-In Wine Refri...  Major Appliances   \n45682         Broan 30W in. QP2 Under Cabinet Range Hood  Major Appliances   \n84940                                  Samsung DV5451AGW  Major Appliances   \n1873   Avalon Top Loading Water Cooler Dispenser - Ho...  Major Appliances   \n53872  LG LDF7561 Fully Integrated Dishwasher with He...  Major Appliances   \n\n       helpful_votes  total_votes vine verified_purchase  \\\n71963              5           14    N                 N   \n15508              0            0    N                 Y   \n3110               6            6    N                 N   \n88804              0            0    N                 N   \n18295              0            0    N                 Y   \n...              ...          ...  ...               ...   \n62973             11           12    N                 Y   \n45682              9            9    N                 Y   \n84940              4            4    N                 N   \n1873             144          156    N                 N   \n53872              0            1    N                 N   \n\n                                         review_headline  \\\n71963                          lg small washer/dryer set   \n15508  very hard to open must be securely mounted no ...   \n3110   15 month useful life - this should be disconti...   \n88804                               Unexpectedly Awesome   \n18295                                            Perfect   \n...                                                  ...   \n62973                                         Very Happy   \n45682  Up until it quit working I though I had made a...   \n84940      Does NOT dry clothes. So not much of a dryer.   \n1873   Avalon water dispenser beat my many previous w...   \n53872                                  Bad build quality   \n\n                                             review_body review_date  \\\n71963  usually rate things hate exactly feel small lg...  2013-04-06   \n15508         hard open must securely mounted provisions  2015-04-16   \n3110   15 months stopped working threw groceries call...  2015-08-07   \n88804  silver version tiny cooler fridge company chri...  2011-06-28   \n18295                      exactly needed get dryer back  2015-03-22   \n...                                                  ...         ...   \n62973  purchased replace space 12 34 garbage compacto...  2013-09-28   \n45682  bought item professionally installed middle ap...  2014-07-07   \n84940  purchased nice looking supposedly good name br...  2012-02-18   \n1873   videoid:8829556f67d2453e377e6459465db27e first...  2015-08-16   \n53872  middle drawer tight pull easily tech take look...  2014-03-01   \n\n       sentiment  \n71963          0  \n15508          1  \n3110           0  \n88804          2  \n18295          2  \n...          ...  \n62973          2  \n45682          0  \n84940          0  \n1873           2  \n53872          0  \n\n[80000 rows x 15 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>marketplace</th>\n      <th>customer_id</th>\n      <th>review_id</th>\n      <th>product_id</th>\n      <th>product_parent</th>\n      <th>product_title</th>\n      <th>product_category</th>\n      <th>helpful_votes</th>\n      <th>total_votes</th>\n      <th>vine</th>\n      <th>verified_purchase</th>\n      <th>review_headline</th>\n      <th>review_body</th>\n      <th>review_date</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>71963</th>\n      <td>US</td>\n      <td>23022807</td>\n      <td>R3IZQ5QBR0C7B7</td>\n      <td>B0039V7JFG</td>\n      <td>184993957</td>\n      <td>LG 3.6 CF FRONT LOAD WASHER DRYER COMBO</td>\n      <td>Major Appliances</td>\n      <td>5</td>\n      <td>14</td>\n      <td>N</td>\n      <td>N</td>\n      <td>lg small washer/dryer set</td>\n      <td>usually rate things hate exactly feel small lg...</td>\n      <td>2013-04-06</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15508</th>\n      <td>US</td>\n      <td>21831333</td>\n      <td>R2LGGHUB944XMT</td>\n      <td>B00EJPHJVK</td>\n      <td>516641616</td>\n      <td>Fantech Lint Trap for Dryer Booster - DBLT4W (...</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>very hard to open must be securely mounted no ...</td>\n      <td>hard open must securely mounted provisions</td>\n      <td>2015-04-16</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3110</th>\n      <td>US</td>\n      <td>11941986</td>\n      <td>R21U3YZPS3MBXG</td>\n      <td>B00HH2YZT6</td>\n      <td>73366442</td>\n      <td>Samsung RF32FMQDBSR 4-Door Refrigerator with C...</td>\n      <td>Major Appliances</td>\n      <td>6</td>\n      <td>6</td>\n      <td>N</td>\n      <td>N</td>\n      <td>15 month useful life - this should be disconti...</td>\n      <td>15 months stopped working threw groceries call...</td>\n      <td>2015-08-07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>88804</th>\n      <td>US</td>\n      <td>46476694</td>\n      <td>R2JZ0YSJ5QEZX4</td>\n      <td>B001VKY8GU</td>\n      <td>232040651</td>\n      <td>Koolatron Coca Cola Personal Cube Fridge</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Unexpectedly Awesome</td>\n      <td>silver version tiny cooler fridge company chri...</td>\n      <td>2011-06-28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18295</th>\n      <td>US</td>\n      <td>48338607</td>\n      <td>R2QENB1J5LBM14</td>\n      <td>B00MZH0OPC</td>\n      <td>394118467</td>\n      <td>( 2 PACK ) 3392519 - DRYER THERMAL FUSE for Wh...</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>0</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Perfect</td>\n      <td>exactly needed get dryer back</td>\n      <td>2015-03-22</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>62973</th>\n      <td>US</td>\n      <td>31634986</td>\n      <td>R173X6QPB1N8SY</td>\n      <td>B004HXDLJ8</td>\n      <td>693470227</td>\n      <td>Whynter BWR-18SD 18 Bottle Built-In Wine Refri...</td>\n      <td>Major Appliances</td>\n      <td>11</td>\n      <td>12</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Very Happy</td>\n      <td>purchased replace space 12 34 garbage compacto...</td>\n      <td>2013-09-28</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>45682</th>\n      <td>US</td>\n      <td>52949439</td>\n      <td>R4YB9KY26NLPP</td>\n      <td>B003GFAY52</td>\n      <td>647457047</td>\n      <td>Broan 30W in. QP2 Under Cabinet Range Hood</td>\n      <td>Major Appliances</td>\n      <td>9</td>\n      <td>9</td>\n      <td>N</td>\n      <td>Y</td>\n      <td>Up until it quit working I though I had made a...</td>\n      <td>bought item professionally installed middle ap...</td>\n      <td>2014-07-07</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>84940</th>\n      <td>US</td>\n      <td>42829199</td>\n      <td>R1W9QEUT7MIYGD</td>\n      <td>B004WP4BAO</td>\n      <td>480751909</td>\n      <td>Samsung DV5451AGW</td>\n      <td>Major Appliances</td>\n      <td>4</td>\n      <td>4</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Does NOT dry clothes. So not much of a dryer.</td>\n      <td>purchased nice looking supposedly good name br...</td>\n      <td>2012-02-18</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1873</th>\n      <td>US</td>\n      <td>19293947</td>\n      <td>R12LFU2ZVPAZSS</td>\n      <td>B0125S2K0M</td>\n      <td>504103070</td>\n      <td>Avalon Top Loading Water Cooler Dispenser - Ho...</td>\n      <td>Major Appliances</td>\n      <td>144</td>\n      <td>156</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Avalon water dispenser beat my many previous w...</td>\n      <td>videoid:8829556f67d2453e377e6459465db27e first...</td>\n      <td>2015-08-16</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>53872</th>\n      <td>US</td>\n      <td>11233134</td>\n      <td>R2S04Z77YZXZAP</td>\n      <td>B007VXJ0HS</td>\n      <td>285649250</td>\n      <td>LG LDF7561 Fully Integrated Dishwasher with He...</td>\n      <td>Major Appliances</td>\n      <td>0</td>\n      <td>1</td>\n      <td>N</td>\n      <td>N</td>\n      <td>Bad build quality</td>\n      <td>middle drawer tight pull easily tech take look...</td>\n      <td>2014-03-01</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>80000 rows × 15 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.965295200Z",
     "start_time": "2024-05-19T18:19:07.918484400Z"
    }
   },
   "id": "61075fa8ce779b40"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Final dataset\n",
    "- 80 000 instances\n",
    "- NEGATIVE 21 334\n",
    "- NEUTRAL 5 674\n",
    "- POSITIVE 52 992 \n",
    "- **Quite imbalanced -> experiment with class weights**\n",
    "- 90:10 train:test split"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f66880c2eaddb91e"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n2    52992\n0    21334\n1     5674\nName: count, dtype: int64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.965800200Z",
     "start_time": "2024-05-19T18:19:07.922999600Z"
    }
   },
   "id": "51a301bdbbc85fa6"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "df_multimodal = df\n",
    "df = df[['review_body', 'sentiment']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['review_body'], df['sentiment'], random_state=42, test_size=0.1, stratify=df['sentiment']\n",
    ")\n",
    "#Train-val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.1, stratify=y_train, random_state=42\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.983435200Z",
     "start_time": "2024-05-19T18:19:07.929049800Z"
    }
   },
   "id": "3f410caa3e666495"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n2    42924\n0    17280\n1     4596\nName: count, dtype: int64"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.983435200Z",
     "start_time": "2024-05-19T18:19:07.967807Z"
    }
   },
   "id": "f665ddc4246c79dc"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "sentiment\n2    5299\n0    2134\n1     567\nName: count, dtype: int64"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:07.983435200Z",
     "start_time": "2024-05-19T18:19:07.971921Z"
    }
   },
   "id": "bb12164d07568651"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Recurrent Neural Network"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb0864a37a48ec44"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:19:07.982278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:07.982427: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:07.982504: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:08.115023: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:08.115097: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:08.115104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-05-19 20:19:08.115159: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:0b:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-05-19 20:19:08.115177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 9558 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070, pci bus id: 0000:0b:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, y_test))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:19:08.678347800Z",
     "start_time": "2024-05-19T18:19:08.026665200Z"
    }
   },
   "id": "96e28c1a9c77e91f"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "max_tokens = 8000\n",
    "\n",
    "text_vectorization = TextVectorization(\n",
    "    ngrams=1,\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length\n",
    ")\n",
    "\n",
    "text_only_train_ds = train_dataset.map(lambda x, y: x)\n",
    "text_vectorization.adapt(text_only_train_ds)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:53.389265900Z",
     "start_time": "2024-05-19T18:19:08.677339300Z"
    }
   },
   "id": "f97e30531d7c3605"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['', '[UNK]', 'one', 'water', 'would', 'great', 'like', 'get',\n       'unit', 'ice', 'time', 'use', 'machine', 'well', 'good', 'washer',\n       'product', 'works', 'new', '2'], dtype='<U15')"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(text_vectorization.get_vocabulary())\n",
    "vocab[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:53.400162200Z",
     "start_time": "2024-05-19T18:22:53.391791500Z"
    }
   },
   "id": "f0b6e642b87c8ac5"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Define a function to vectorize the texts\n",
    "def vectorize_text(text, label):\n",
    "    return text_vectorization(text), label\n",
    "\n",
    "# Apply the vectorization to the training, validation, and test datasets\n",
    "train_ds = (train_dataset.map(vectorize_text).cache()\n",
    "            .shuffle(10000)\n",
    "            .batch(32)\n",
    "            .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "val_ds = (validation_dataset.map(vectorize_text)\n",
    "          .cache()\n",
    "          .batch(32)\n",
    "          .prefetch(buffer_size=tf.data.AUTOTUNE))\n",
    "\n",
    "test_ds = (test_dataset.map(vectorize_text)\n",
    "           .cache()\n",
    "           .batch(32)\n",
    "           .prefetch(buffer_size=tf.data.AUTOTUNE))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:53.565398400Z",
     "start_time": "2024-05-19T18:22:53.413137800Z"
    }
   },
   "id": "b7526999eb3cc981"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs data type <dtype: 'int64'>\n",
      "inputs shape (32, 100)\n",
      "targets data type <dtype: 'int64'>\n",
      "targets shape (32,)\n",
      "inputs[0] tf.Tensor(\n",
      "[[ 145   58 1905 ...  998 2614  523]\n",
      " [  72 1974  581 ...    0    0    0]\n",
      " [ 162   36  174 ...    0    0    0]\n",
      " ...\n",
      " [  51  907  394 ...    0    0    0]\n",
      " [2063  227   31 ...    0    0    0]\n",
      " [   2  329   58 ...    0    0    0]], shape=(32, 100), dtype=int64)\n",
      "targets[0] tf.Tensor([0 0 2 0 0 2 2 2 2 2 2 2 2 0 2 2 2 0 2 2 2 0 2 2 2 2 2 0 2 2 2 2], shape=(32,), dtype=int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:22:54.994508: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs data type\",inputs.dtype)\n",
    "    print(\"inputs shape\",inputs.shape)\n",
    "    print(\"targets data type\",targets.dtype)\n",
    "    print(\"targets shape\",targets.shape)\n",
    "    print(\"inputs[0]\", inputs)\n",
    "    #print(inputs[0].numpy().decode('utf-8'))\n",
    "    print(\"targets[0]\", targets)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:55.005646500Z",
     "start_time": "2024-05-19T18:22:53.566398100Z"
    }
   },
   "id": "f882d9aa66e1ba65"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "negative, neutral, positive = np.bincount(df['sentiment'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:55.005646500Z",
     "start_time": "2024-05-19T18:22:55.002574900Z"
    }
   },
   "id": "6b3a385080e2f412"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "(21334, 5674, 52992)"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative, neutral, positive"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:55.012427300Z",
     "start_time": "2024-05-19T18:22:55.004647400Z"
    }
   },
   "id": "7b169e55dc72c381"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight for class 0: 1.25\n",
      "Weight for class 1: 4.70\n",
      "Weight for class 2: 0.50\n"
     ]
    }
   ],
   "source": [
    "### proportional calculation of weights \n",
    "\n",
    "weight_for_0 = (1 / negative) * (df.shape[0] / 3)\n",
    "weight_for_1 = (1 / neutral) * (df.shape[0] / 3)\n",
    "weight_for_2 = (1 / positive) * (df.shape[0] / 3)\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1, 2: weight_for_2}\n",
    "\n",
    "print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "print('Weight for class 1: {:.2f}'.format(weight_for_1))\n",
    "print('Weight for class 2: {:.2f}'.format(weight_for_2))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:55.019425200Z",
     "start_time": "2024-05-19T18:22:55.011430Z"
    }
   },
   "id": "ead80fe388cbe495"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def get_conf_matrix(model):\n",
    "    predictions = model.predict(test_ds)\n",
    "    classes = tf.argmax(predictions, axis=-1)\n",
    "    intensity = confusion_matrix(y_test, list(classes.numpy()))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix = intensity, display_labels=[0,1,2])\n",
    "    disp.plot()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:55.051940500Z",
     "start_time": "2024-05-19T18:22:55.016425900Z"
    }
   },
   "id": "921139b146fe469b"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "def create_RNN(max_length, embedding_dim = 128, lstm_units = 16, optimizer = 'sgd', metrics = 'accuracy'):\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "\n",
    "    x = layers.Embedding(max_tokens, embedding_dim)(inputs)\n",
    "\n",
    "    # Bidirectional LSTM layer\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm_units))(x)\n",
    "\n",
    "    # Output layer for binary classification\n",
    "    outputs = layers.Dense(3, activation=\"sigmoid\")(x)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[metrics])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_CNN(max_length, embedding_dim = 128, dropout_rate = 0.5, optimizer = 'sgd', metrics = 'accuracy', activation = 'relu'):\n",
    "\n",
    "    inputs = keras.Input(shape=(max_length,), dtype=\"int64\")\n",
    "\n",
    "    x = layers.Embedding(max_tokens, embedding_dim, input_length=max_length)(inputs)\n",
    "    x = layers.Conv1D(filters = 128, kernel_size =  5, activation='relu')(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=64, kernel_size=4, padding='same', activation=activation)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=4, padding='same', activation=activation)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Conv1D(filters=32, kernel_size=4, padding='same', activation=activation)(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dense(10, activation = 'sigmoid')(x)\n",
    "    x = layers.Dropout(dropout_rate)(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "\n",
    "    outputs = layers.Dense(3, activation = 'sigmoid')(x)\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[metrics])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:22:55.061457200Z",
     "start_time": "2024-05-19T18:22:55.025428600Z"
    }
   },
   "id": "fb777943bfdfa9b7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Train Reccurent Neural Network\n",
    "- train baseline model with basic parameters\n",
    "- train baseline model with basic parameters + adjusted weights\n",
    "- implement hyperparameter tuning using TFDF "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c815af443cec87e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 RNN with default weights and default hyperparameters"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11f4ec4713a7667f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:22:55.110693: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: Permission denied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, 100, 128)          1024000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 32)                18560     \n",
      " al)                                                             \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1042659 (3.98 MB)\n",
      "Trainable params: 1042659 (3.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:22:58.298016: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-05-19 20:22:58.373692: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f03e9ad73e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-19 20:22:58.373726: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4070, Compute Capability 8.9\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1716142978.399132  410299 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 54s 25ms/step - loss: 0.8086 - accuracy: 0.6624 - val_loss: 0.7901 - val_accuracy: 0.6624\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7620 - accuracy: 0.6627 - val_loss: 0.7359 - val_accuracy: 0.6821\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6886 - accuracy: 0.7297 - val_loss: 0.6119 - val_accuracy: 0.7711\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.5784 - accuracy: 0.7899 - val_loss: 0.6455 - val_accuracy: 0.7500\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.5204 - accuracy: 0.8169 - val_loss: 0.5817 - val_accuracy: 0.7808\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4868 - accuracy: 0.8309 - val_loss: 0.5733 - val_accuracy: 0.7885\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.4635 - accuracy: 0.8393 - val_loss: 0.5592 - val_accuracy: 0.7981\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4466 - accuracy: 0.8448 - val_loss: 0.5271 - val_accuracy: 0.8125\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.4346 - accuracy: 0.8493 - val_loss: 0.5126 - val_accuracy: 0.8174\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.4255 - accuracy: 0.8526 - val_loss: 0.5175 - val_accuracy: 0.8183\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.4179 - accuracy: 0.8558 - val_loss: 0.5400 - val_accuracy: 0.8131\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.4118 - accuracy: 0.8577 - val_loss: 0.5488 - val_accuracy: 0.8128\n",
      "250/250 [==============================] - 2s 10ms/step - loss: 0.5140 - accuracy: 0.8169\n",
      "Test dataset accuracy: 0.8168749809265137\n",
      "250/250 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_RNN(max_length)\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.002, restore_best_weights=True),\n",
    "]\n",
    "history = model.fit(train_ds.cache(), epochs=20, validation_data=val_ds.cache(), callbacks=callbacks)\n",
    "print(f\"Test dataset accuracy: {model.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:31:01.279802800Z",
     "start_time": "2024-05-19T18:22:55.028425600Z"
    }
   },
   "id": "1f479272e4a3fe33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.1 RNN with adjusted weights and default hyperparameters\n",
    "- Weight for class 0: 1.25\n",
    "- Weight for class 1: 4.70\n",
    "- Weight for class 2: 0.50\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c6f1c968efbe62e8"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_1 (Embedding)     (None, 100, 128)          1024000   \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 32)                18560     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 3)                 99        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1042659 (3.98 MB)\n",
      "Trainable params: 1042659 (3.98 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 52s 25ms/step - loss: 1.0756 - accuracy: 0.5161 - val_loss: 1.0391 - val_accuracy: 0.5726\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 1.0341 - accuracy: 0.6031 - val_loss: 0.9645 - val_accuracy: 0.6336\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9414 - accuracy: 0.6702 - val_loss: 0.8931 - val_accuracy: 0.6514\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 38s 19ms/step - loss: 0.8537 - accuracy: 0.6868 - val_loss: 0.8152 - val_accuracy: 0.6329\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8015 - accuracy: 0.6928 - val_loss: 0.7885 - val_accuracy: 0.6189\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7700 - accuracy: 0.6960 - val_loss: 0.7524 - val_accuracy: 0.6344\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7469 - accuracy: 0.7052 - val_loss: 0.7676 - val_accuracy: 0.6162\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7291 - accuracy: 0.7092 - val_loss: 0.6574 - val_accuracy: 0.7060\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.7153 - accuracy: 0.7112 - val_loss: 0.6677 - val_accuracy: 0.6899\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.6981 - accuracy: 0.7173 - val_loss: 0.6823 - val_accuracy: 0.6772\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6865 - accuracy: 0.7215 - val_loss: 0.6591 - val_accuracy: 0.6953\n",
      "250/250 [==============================] - 2s 9ms/step - loss: 0.6551 - accuracy: 0.7079\n",
      "Test dataset accuracy: 0.7078750133514404\n",
      "250/250 [==============================] - 2s 8ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embedding_dim = 128\n",
    "model = create_RNN(max_length, embedding_dim)\n",
    "model.summary()\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.002, restore_best_weights=True),\n",
    "]\n",
    "history = model.fit(train_ds.cache(), epochs=20, validation_data=val_ds.cache(), callbacks=callbacks, class_weight=class_weight)\n",
    "print(f\"Test dataset accuracy: {model.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:38:30.558952700Z",
     "start_time": "2024-05-19T18:31:01.279802800Z"
    }
   },
   "id": "811dc9379204510c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3.2. RNN with hyperparameter tuning"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f5729d8fab009b6d"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "def grid_search_RNN(epochs=20, patience=3):\n",
    "    best_model = None\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    for embedding_dim in param_grid_RNN['embedding_dim']:\n",
    "        for lstm_unit in param_grid_RNN['lstm_units']:\n",
    "            for optimizer in param_grid_RNN['optimizer']:\n",
    "                model = create_RNN(max_length=max_length,\n",
    "                                   embedding_dim=embedding_dim,\n",
    "                                   lstm_units = lstm_unit,\n",
    "                                   optimizer=optimizer)\n",
    "\n",
    "                callbacks = [\n",
    "                    keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "                ]\n",
    "\n",
    "                history = model.fit(train_ds.cache(), epochs=epochs,\n",
    "                                    validation_data=val_ds.cache(),\n",
    "                                    callbacks=callbacks,\n",
    "                                    class_weight=class_weight)\n",
    "\n",
    "                val_acc = history.history['val_accuracy'][-1]  # Get last validation accuracy\n",
    "                if val_acc > best_accuracy:\n",
    "                    best_model = model\n",
    "                    best_accuracy = val_acc\n",
    "    return best_model, best_accuracy\n",
    "\n",
    "# Example usage (assuming you have prepared your train_data and val_data)\n",
    "\n",
    "# Example usage (assuming you have your training data)\n",
    "param_grid_RNN = {\n",
    "    'embedding_dim': [64, 128, 256],\n",
    "    'lstm_units': [16, 32, 64],\n",
    "    'optimizer': ['adam', 'sgd', 'adagrad'],\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:45:05.686066900Z",
     "start_time": "2024-05-19T18:45:05.643977800Z"
    }
   },
   "id": "bc68a6ea6a7536d3"
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-19 20:45:22.930945: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2024-05-19 20:45:22.935753: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025/2025 [==============================] - 65s 31ms/step - loss: 0.7504 - accuracy: 0.7144 - val_loss: 0.6242 - val_accuracy: 0.7237\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.5976 - accuracy: 0.7731 - val_loss: 0.6256 - val_accuracy: 0.7314\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.5183 - accuracy: 0.8037 - val_loss: 0.6185 - val_accuracy: 0.7375\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.4567 - accuracy: 0.8277 - val_loss: 0.7039 - val_accuracy: 0.7276\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.4150 - accuracy: 0.8400 - val_loss: 0.7484 - val_accuracy: 0.7271\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.3599 - accuracy: 0.8615 - val_loss: 0.6095 - val_accuracy: 0.8047\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.3111 - accuracy: 0.8795 - val_loss: 0.6473 - val_accuracy: 0.8012\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.2813 - accuracy: 0.8902 - val_loss: 0.6655 - val_accuracy: 0.8078\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.2548 - accuracy: 0.8985 - val_loss: 0.6917 - val_accuracy: 0.8096\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 54s 26ms/step - loss: 1.0935 - accuracy: 0.4335 - val_loss: 1.0577 - val_accuracy: 0.6540\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0663 - accuracy: 0.5542 - val_loss: 1.0137 - val_accuracy: 0.6103\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0461 - accuracy: 0.5931 - val_loss: 0.9837 - val_accuracy: 0.6404\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0024 - accuracy: 0.6447 - val_loss: 0.8275 - val_accuracy: 0.7585\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.9072 - accuracy: 0.6926 - val_loss: 0.7398 - val_accuracy: 0.7574\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.8407 - accuracy: 0.7072 - val_loss: 0.7860 - val_accuracy: 0.7161\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7980 - accuracy: 0.7118 - val_loss: 0.6623 - val_accuracy: 0.7494\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7748 - accuracy: 0.7123 - val_loss: 0.6175 - val_accuracy: 0.7572\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7519 - accuracy: 0.7172 - val_loss: 0.6149 - val_accuracy: 0.7519\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.7321 - accuracy: 0.7198 - val_loss: 0.6021 - val_accuracy: 0.7639\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7186 - accuracy: 0.7224 - val_loss: 0.6802 - val_accuracy: 0.6904\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7070 - accuracy: 0.7243 - val_loss: 0.6123 - val_accuracy: 0.7522\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6974 - accuracy: 0.7267 - val_loss: 0.5916 - val_accuracy: 0.7528\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6853 - accuracy: 0.7316 - val_loss: 0.5895 - val_accuracy: 0.7576\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6757 - accuracy: 0.7349 - val_loss: 0.5763 - val_accuracy: 0.7628\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6681 - accuracy: 0.7376 - val_loss: 0.5639 - val_accuracy: 0.7682\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.6576 - accuracy: 0.7442 - val_loss: 0.5672 - val_accuracy: 0.7635\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 0.6524 - accuracy: 0.7465 - val_loss: 0.5646 - val_accuracy: 0.7588\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6407 - accuracy: 0.7549 - val_loss: 0.5710 - val_accuracy: 0.7617\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 58s 28ms/step - loss: 1.0992 - accuracy: 0.2656 - val_loss: 1.0953 - val_accuracy: 0.4489\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0973 - accuracy: 0.5577 - val_loss: 1.0899 - val_accuracy: 0.6236\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0958 - accuracy: 0.6361 - val_loss: 1.0863 - val_accuracy: 0.6519\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0941 - accuracy: 0.6507 - val_loss: 1.0827 - val_accuracy: 0.6585\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0914 - accuracy: 0.6609 - val_loss: 1.0768 - val_accuracy: 0.6704\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 40s 20ms/step - loss: 1.0843 - accuracy: 0.6695 - val_loss: 1.0549 - val_accuracy: 0.6557\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0637 - accuracy: 0.6417 - val_loss: 1.0264 - val_accuracy: 0.6347\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0509 - accuracy: 0.6325 - val_loss: 1.0171 - val_accuracy: 0.6300\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0432 - accuracy: 0.6315 - val_loss: 1.0075 - val_accuracy: 0.6319\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0356 - accuracy: 0.6333 - val_loss: 0.9970 - val_accuracy: 0.6344\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0268 - accuracy: 0.6383 - val_loss: 0.9847 - val_accuracy: 0.6407\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0160 - accuracy: 0.6466 - val_loss: 0.9696 - val_accuracy: 0.6521\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0020 - accuracy: 0.6605 - val_loss: 0.9507 - val_accuracy: 0.6719\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.9809 - accuracy: 0.6869 - val_loss: 0.9237 - val_accuracy: 0.7033\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.9388 - accuracy: 0.7429 - val_loss: 0.8316 - val_accuracy: 0.7704\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9047 - accuracy: 0.7754 - val_loss: 0.8065 - val_accuracy: 0.7800\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8869 - accuracy: 0.7815 - val_loss: 0.7907 - val_accuracy: 0.7831\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8726 - accuracy: 0.7850 - val_loss: 0.7777 - val_accuracy: 0.7853\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8606 - accuracy: 0.7866 - val_loss: 0.7660 - val_accuracy: 0.7871\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8502 - accuracy: 0.7869 - val_loss: 0.7564 - val_accuracy: 0.7892\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 66s 32ms/step - loss: 0.7477 - accuracy: 0.7191 - val_loss: 0.5709 - val_accuracy: 0.7597\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.5981 - accuracy: 0.7754 - val_loss: 0.5602 - val_accuracy: 0.7669\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.5301 - accuracy: 0.8052 - val_loss: 0.6485 - val_accuracy: 0.7415\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.4666 - accuracy: 0.8274 - val_loss: 0.5810 - val_accuracy: 0.7815\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.4122 - accuracy: 0.8471 - val_loss: 0.6002 - val_accuracy: 0.7868\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 55s 26ms/step - loss: 1.0907 - accuracy: 0.4553 - val_loss: 1.0368 - val_accuracy: 0.5983\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0553 - accuracy: 0.5855 - val_loss: 1.0285 - val_accuracy: 0.5922\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0425 - accuracy: 0.5913 - val_loss: 0.9965 - val_accuracy: 0.6142\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.9753 - accuracy: 0.6431 - val_loss: 0.9441 - val_accuracy: 0.6492\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8849 - accuracy: 0.6909 - val_loss: 0.7768 - val_accuracy: 0.7165\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.8265 - accuracy: 0.6995 - val_loss: 0.6982 - val_accuracy: 0.7310\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7882 - accuracy: 0.6991 - val_loss: 0.6465 - val_accuracy: 0.7543\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7620 - accuracy: 0.7039 - val_loss: 0.6146 - val_accuracy: 0.7633\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7419 - accuracy: 0.7088 - val_loss: 0.6012 - val_accuracy: 0.7653\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7261 - accuracy: 0.7127 - val_loss: 0.5966 - val_accuracy: 0.7632\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7128 - accuracy: 0.7166 - val_loss: 0.5859 - val_accuracy: 0.7657\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7033 - accuracy: 0.7183 - val_loss: 0.5939 - val_accuracy: 0.7558\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.6927 - accuracy: 0.7225 - val_loss: 0.5643 - val_accuracy: 0.7726\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6790 - accuracy: 0.7288 - val_loss: 0.5544 - val_accuracy: 0.7796\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6687 - accuracy: 0.7335 - val_loss: 0.5431 - val_accuracy: 0.7860\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.6579 - accuracy: 0.7408 - val_loss: 0.5298 - val_accuracy: 0.7939\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6478 - accuracy: 0.7457 - val_loss: 0.5285 - val_accuracy: 0.7943\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.6417 - accuracy: 0.7502 - val_loss: 0.5167 - val_accuracy: 0.8031\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 45s 22ms/step - loss: 0.6368 - accuracy: 0.7520 - val_loss: 0.5174 - val_accuracy: 0.8012\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.6259 - accuracy: 0.7585 - val_loss: 0.5111 - val_accuracy: 0.8032\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 58s 28ms/step - loss: 1.0977 - accuracy: 0.5741 - val_loss: 1.0901 - val_accuracy: 0.6203\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0966 - accuracy: 0.6176 - val_loss: 1.0879 - val_accuracy: 0.6193\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 1.0955 - accuracy: 0.6213 - val_loss: 1.0855 - val_accuracy: 0.6199\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0941 - accuracy: 0.6225 - val_loss: 1.0823 - val_accuracy: 0.6190\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0921 - accuracy: 0.6195 - val_loss: 1.0770 - val_accuracy: 0.6142\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0876 - accuracy: 0.6004 - val_loss: 1.0595 - val_accuracy: 0.5810\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0704 - accuracy: 0.6156 - val_loss: 1.0314 - val_accuracy: 0.6290\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0559 - accuracy: 0.6195 - val_loss: 1.0322 - val_accuracy: 0.6226\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0507 - accuracy: 0.6128 - val_loss: 1.0264 - val_accuracy: 0.6151\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0463 - accuracy: 0.6092 - val_loss: 1.0195 - val_accuracy: 0.6094\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0416 - accuracy: 0.6081 - val_loss: 1.0120 - val_accuracy: 0.6079\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 1.0364 - accuracy: 0.6082 - val_loss: 1.0035 - val_accuracy: 0.6079\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0302 - accuracy: 0.6102 - val_loss: 0.9936 - val_accuracy: 0.6097\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0226 - accuracy: 0.6138 - val_loss: 0.9814 - val_accuracy: 0.6139\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0130 - accuracy: 0.6202 - val_loss: 0.9662 - val_accuracy: 0.6247\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0006 - accuracy: 0.6320 - val_loss: 0.9466 - val_accuracy: 0.6421\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9834 - accuracy: 0.6504 - val_loss: 0.9199 - val_accuracy: 0.6653\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9563 - accuracy: 0.6830 - val_loss: 0.8768 - val_accuracy: 0.7092\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9056 - accuracy: 0.7511 - val_loss: 0.7806 - val_accuracy: 0.7746\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8762 - accuracy: 0.7680 - val_loss: 0.7596 - val_accuracy: 0.7704\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 67s 32ms/step - loss: 0.7482 - accuracy: 0.7195 - val_loss: 0.5681 - val_accuracy: 0.7599\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.5999 - accuracy: 0.7776 - val_loss: 0.5037 - val_accuracy: 0.7993\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.5300 - accuracy: 0.8055 - val_loss: 0.5203 - val_accuracy: 0.7958\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.4750 - accuracy: 0.8248 - val_loss: 0.5287 - val_accuracy: 0.8019\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.4139 - accuracy: 0.8448 - val_loss: 0.5459 - val_accuracy: 0.7996\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 53s 25ms/step - loss: 1.0957 - accuracy: 0.4165 - val_loss: 1.0695 - val_accuracy: 0.6562\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0675 - accuracy: 0.5598 - val_loss: 1.0217 - val_accuracy: 0.6029\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0515 - accuracy: 0.5783 - val_loss: 1.0050 - val_accuracy: 0.6106\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0235 - accuracy: 0.6015 - val_loss: 0.9185 - val_accuracy: 0.6807\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.9463 - accuracy: 0.6452 - val_loss: 0.7987 - val_accuracy: 0.7210\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8669 - accuracy: 0.6880 - val_loss: 0.7369 - val_accuracy: 0.7361\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8117 - accuracy: 0.7048 - val_loss: 0.7235 - val_accuracy: 0.7072\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7786 - accuracy: 0.7057 - val_loss: 0.7021 - val_accuracy: 0.7086\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 41s 20ms/step - loss: 0.7601 - accuracy: 0.7092 - val_loss: 0.7392 - val_accuracy: 0.6865\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.7383 - accuracy: 0.7139 - val_loss: 0.7262 - val_accuracy: 0.6910\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.7235 - accuracy: 0.7174 - val_loss: 0.7262 - val_accuracy: 0.6862\n",
      "Epoch 1/20\n",
      "2025/2025 [==============================] - 57s 27ms/step - loss: 1.0981 - accuracy: 0.2733 - val_loss: 1.0959 - val_accuracy: 0.4014\n",
      "Epoch 2/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0971 - accuracy: 0.4653 - val_loss: 1.0931 - val_accuracy: 0.5011\n",
      "Epoch 3/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0960 - accuracy: 0.5209 - val_loss: 1.0903 - val_accuracy: 0.5346\n",
      "Epoch 4/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0943 - accuracy: 0.5453 - val_loss: 1.0860 - val_accuracy: 0.5512\n",
      "Epoch 5/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0911 - accuracy: 0.5514 - val_loss: 1.0755 - val_accuracy: 0.5571\n",
      "Epoch 6/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0758 - accuracy: 0.6012 - val_loss: 1.0223 - val_accuracy: 0.6186\n",
      "Epoch 7/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0551 - accuracy: 0.6052 - val_loss: 1.0300 - val_accuracy: 0.5974\n",
      "Epoch 8/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0510 - accuracy: 0.5962 - val_loss: 1.0259 - val_accuracy: 0.5899\n",
      "Epoch 9/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0471 - accuracy: 0.5926 - val_loss: 1.0201 - val_accuracy: 0.5882\n",
      "Epoch 10/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0425 - accuracy: 0.5921 - val_loss: 1.0128 - val_accuracy: 0.5900\n",
      "Epoch 11/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0370 - accuracy: 0.5935 - val_loss: 1.0036 - val_accuracy: 0.5939\n",
      "Epoch 12/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 1.0298 - accuracy: 0.5976 - val_loss: 0.9915 - val_accuracy: 0.6001\n",
      "Epoch 13/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0200 - accuracy: 0.6049 - val_loss: 0.9745 - val_accuracy: 0.6094\n",
      "Epoch 14/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 1.0053 - accuracy: 0.6183 - val_loss: 0.9470 - val_accuracy: 0.6263\n",
      "Epoch 15/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.9760 - accuracy: 0.6502 - val_loss: 0.8820 - val_accuracy: 0.6818\n",
      "Epoch 16/20\n",
      "2025/2025 [==============================] - 44s 22ms/step - loss: 0.9136 - accuracy: 0.7293 - val_loss: 0.8026 - val_accuracy: 0.7553\n",
      "Epoch 17/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8781 - accuracy: 0.7557 - val_loss: 0.7615 - val_accuracy: 0.7638\n",
      "Epoch 18/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8581 - accuracy: 0.7585 - val_loss: 0.7395 - val_accuracy: 0.7661\n",
      "Epoch 19/20\n",
      "2025/2025 [==============================] - 42s 21ms/step - loss: 0.8437 - accuracy: 0.7574 - val_loss: 0.7276 - val_accuracy: 0.7672\n",
      "Epoch 20/20\n",
      "2025/2025 [==============================] - 43s 21ms/step - loss: 0.8320 - accuracy: 0.7545 - val_loss: 0.7195 - val_accuracy: 0.7678\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "best_CNN, acc_CNN = grid_search_RNN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T20:17:58.304886700Z",
     "start_time": "2024-05-19T18:45:21.606315300Z"
    }
   },
   "id": "9dc314cd24f69bae"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "def grid_search_CNN(epochs=30, patience=3):\n",
    "    best_model = None\n",
    "    best_accuracy = 0.0\n",
    "    \n",
    "    for embedding_dim in param_grid_CNN['embedding_dim']:\n",
    "        for dropout_rate in param_grid_CNN['dropout_rate']:\n",
    "            for optimizer in param_grid_CNN['optimizer']:\n",
    "                for activation in param_grid_CNN['activation']:\n",
    "                    model = create_CNN(max_length=max_length,\n",
    "                                       embedding_dim=embedding_dim,\n",
    "                                       dropout_rate=dropout_rate,\n",
    "                                       optimizer=optimizer,\n",
    "                                       activation=activation)\n",
    "\n",
    "                    callbacks = [\n",
    "                        keras.callbacks.EarlyStopping(monitor='val_loss', patience=patience)\n",
    "                    ]\n",
    "\n",
    "                    history = model.fit(train_ds.cache(), epochs=epochs,\n",
    "                                        validation_data=val_ds.cache(),\n",
    "                                        callbacks=callbacks,\n",
    "                                        class_weight=class_weight)\n",
    "\n",
    "                    val_acc = history.history['val_accuracy'][-1]  # Get last validation accuracy\n",
    "                    if val_acc > best_accuracy:\n",
    "                        best_model = model\n",
    "                        best_accuracy = val_acc\n",
    "    return best_model, best_accuracy\n",
    "\n",
    "# Example usage (assuming you have prepared your train_data and val_data)\n",
    "\n",
    "# Example usage (assuming you have your training data)\n",
    "param_grid_CNN = {\n",
    "    'embedding_dim': [64, 128, 256],  \n",
    "    'dropout_rate': [0.2, 0.3, 0.5],  \n",
    "    'optimizer': ['adam', 'sgd'], \n",
    "    'activation': ['relu', 'leaky_relu']  \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T20:17:58.310390600Z",
     "start_time": "2024-05-19T20:17:58.303882700Z"
    }
   },
   "id": "203c7a48d4551f53"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8500 - accuracy: 0.6691 - val_loss: 0.6882 - val_accuracy: 0.7058\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6950 - accuracy: 0.7423 - val_loss: 0.6283 - val_accuracy: 0.7186\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6112 - accuracy: 0.7758 - val_loss: 0.5662 - val_accuracy: 0.7632\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5427 - accuracy: 0.8080 - val_loss: 0.6829 - val_accuracy: 0.7239\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4834 - accuracy: 0.8342 - val_loss: 0.7022 - val_accuracy: 0.7188\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4336 - accuracy: 0.8544 - val_loss: 0.6836 - val_accuracy: 0.7411\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 38s 18ms/step - loss: 0.8311 - accuracy: 0.6820 - val_loss: 0.6274 - val_accuracy: 0.7349\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6746 - accuracy: 0.7508 - val_loss: 0.5761 - val_accuracy: 0.7651\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5943 - accuracy: 0.7830 - val_loss: 0.5480 - val_accuracy: 0.7815\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5253 - accuracy: 0.8136 - val_loss: 0.5534 - val_accuracy: 0.7950\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.4668 - accuracy: 0.8368 - val_loss: 0.5886 - val_accuracy: 0.7914\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4174 - accuracy: 0.8582 - val_loss: 0.6288 - val_accuracy: 0.7664\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 26s 13ms/step - loss: 1.1270 - accuracy: 0.3303 - val_loss: 1.0604 - val_accuracy: 0.6396\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0916 - accuracy: 0.4311 - val_loss: 1.0246 - val_accuracy: 0.6275\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 1.0702 - accuracy: 0.5289 - val_loss: 1.0273 - val_accuracy: 0.6046\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0641 - accuracy: 0.5413 - val_loss: 1.0198 - val_accuracy: 0.6040\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 1.0623 - accuracy: 0.5518 - val_loss: 1.0177 - val_accuracy: 0.6039\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0603 - accuracy: 0.5536 - val_loss: 1.0180 - val_accuracy: 0.6028\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0598 - accuracy: 0.5531 - val_loss: 1.0131 - val_accuracy: 0.6064\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0579 - accuracy: 0.5608 - val_loss: 1.0144 - val_accuracy: 0.6087\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0470 - accuracy: 0.5772 - val_loss: 0.9640 - val_accuracy: 0.6529\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.9625 - accuracy: 0.6434 - val_loss: 0.8394 - val_accuracy: 0.7003\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.8892 - accuracy: 0.6816 - val_loss: 0.7508 - val_accuracy: 0.7329\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.8390 - accuracy: 0.7033 - val_loss: 0.6903 - val_accuracy: 0.7546\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7987 - accuracy: 0.7078 - val_loss: 0.6640 - val_accuracy: 0.7357\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7711 - accuracy: 0.7061 - val_loss: 0.6341 - val_accuracy: 0.7419\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7457 - accuracy: 0.7075 - val_loss: 0.6113 - val_accuracy: 0.7360\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7299 - accuracy: 0.7079 - val_loss: 0.6009 - val_accuracy: 0.7386\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7166 - accuracy: 0.7119 - val_loss: 0.5950 - val_accuracy: 0.7386\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7068 - accuracy: 0.7117 - val_loss: 0.5948 - val_accuracy: 0.7371\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6959 - accuracy: 0.7154 - val_loss: 0.5914 - val_accuracy: 0.7417\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6880 - accuracy: 0.7176 - val_loss: 0.5846 - val_accuracy: 0.7396\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6804 - accuracy: 0.7200 - val_loss: 0.5785 - val_accuracy: 0.7457\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6721 - accuracy: 0.7211 - val_loss: 0.5729 - val_accuracy: 0.7490\n",
      "Epoch 23/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6669 - accuracy: 0.7235 - val_loss: 0.5776 - val_accuracy: 0.7392\n",
      "Epoch 24/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6601 - accuracy: 0.7238 - val_loss: 0.5749 - val_accuracy: 0.7460\n",
      "Epoch 25/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6544 - accuracy: 0.7250 - val_loss: 0.5751 - val_accuracy: 0.7392\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 25s 12ms/step - loss: 1.1292 - accuracy: 0.3303 - val_loss: 1.1152 - val_accuracy: 0.0710\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1113 - accuracy: 0.3337 - val_loss: 1.1188 - val_accuracy: 0.0710\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0955 - accuracy: 0.3895 - val_loss: 1.0771 - val_accuracy: 0.4994\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0701 - accuracy: 0.5310 - val_loss: 1.0626 - val_accuracy: 0.5340\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0626 - accuracy: 0.5452 - val_loss: 1.0600 - val_accuracy: 0.5308\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0623 - accuracy: 0.5483 - val_loss: 1.0633 - val_accuracy: 0.5254\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0605 - accuracy: 0.5545 - val_loss: 1.0570 - val_accuracy: 0.5399\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0596 - accuracy: 0.5570 - val_loss: 1.0551 - val_accuracy: 0.5397\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0589 - accuracy: 0.5614 - val_loss: 1.0557 - val_accuracy: 0.5368\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0570 - accuracy: 0.5625 - val_loss: 1.0495 - val_accuracy: 0.5453\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0498 - accuracy: 0.5750 - val_loss: 1.0116 - val_accuracy: 0.5856\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.9777 - accuracy: 0.6331 - val_loss: 0.8544 - val_accuracy: 0.7022\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8949 - accuracy: 0.6772 - val_loss: 0.7538 - val_accuracy: 0.7344\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.8408 - accuracy: 0.6962 - val_loss: 0.7058 - val_accuracy: 0.7218\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7981 - accuracy: 0.7027 - val_loss: 0.6596 - val_accuracy: 0.7275\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7690 - accuracy: 0.7048 - val_loss: 0.6597 - val_accuracy: 0.7108\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7454 - accuracy: 0.7069 - val_loss: 0.6412 - val_accuracy: 0.7094\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7296 - accuracy: 0.7068 - val_loss: 0.6373 - val_accuracy: 0.7083\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7137 - accuracy: 0.7119 - val_loss: 0.6278 - val_accuracy: 0.7079\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7076 - accuracy: 0.7098 - val_loss: 0.6151 - val_accuracy: 0.7142\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6976 - accuracy: 0.7137 - val_loss: 0.6052 - val_accuracy: 0.7186\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6865 - accuracy: 0.7166 - val_loss: 0.6143 - val_accuracy: 0.7099\n",
      "Epoch 23/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6793 - accuracy: 0.7169 - val_loss: 0.6375 - val_accuracy: 0.6925\n",
      "Epoch 24/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6741 - accuracy: 0.7199 - val_loss: 0.6114 - val_accuracy: 0.7135\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 39s 19ms/step - loss: 0.8649 - accuracy: 0.6484 - val_loss: 0.6299 - val_accuracy: 0.7262\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6810 - accuracy: 0.7483 - val_loss: 0.5653 - val_accuracy: 0.7628\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5969 - accuracy: 0.7902 - val_loss: 0.5835 - val_accuracy: 0.7628\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5238 - accuracy: 0.8237 - val_loss: 0.5872 - val_accuracy: 0.7742\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4616 - accuracy: 0.8496 - val_loss: 0.5851 - val_accuracy: 0.7987\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 38s 18ms/step - loss: 0.8440 - accuracy: 0.6773 - val_loss: 0.6019 - val_accuracy: 0.7425\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7007 - accuracy: 0.7313 - val_loss: 0.5572 - val_accuracy: 0.7739\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6325 - accuracy: 0.7607 - val_loss: 0.5731 - val_accuracy: 0.7682\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5684 - accuracy: 0.7896 - val_loss: 0.6949 - val_accuracy: 0.7246\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.5173 - accuracy: 0.8146 - val_loss: 0.6386 - val_accuracy: 0.7700\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 26s 13ms/step - loss: 1.1313 - accuracy: 0.3432 - val_loss: 1.1477 - val_accuracy: 0.0710\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0980 - accuracy: 0.3894 - val_loss: 1.1013 - val_accuracy: 0.3492\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0700 - accuracy: 0.5274 - val_loss: 1.0776 - val_accuracy: 0.4787\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0637 - accuracy: 0.5445 - val_loss: 1.0758 - val_accuracy: 0.4888\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0630 - accuracy: 0.5484 - val_loss: 1.0750 - val_accuracy: 0.4860\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0621 - accuracy: 0.5473 - val_loss: 1.0760 - val_accuracy: 0.4811\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0610 - accuracy: 0.5551 - val_loss: 1.0706 - val_accuracy: 0.5043\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0611 - accuracy: 0.5573 - val_loss: 1.0668 - val_accuracy: 0.5049\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0593 - accuracy: 0.5605 - val_loss: 1.0611 - val_accuracy: 0.5204\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0565 - accuracy: 0.5700 - val_loss: 1.0462 - val_accuracy: 0.5406\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0349 - accuracy: 0.5903 - val_loss: 0.9481 - val_accuracy: 0.6114\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.9348 - accuracy: 0.6506 - val_loss: 0.8633 - val_accuracy: 0.6907\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8620 - accuracy: 0.6819 - val_loss: 0.7805 - val_accuracy: 0.6728\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8130 - accuracy: 0.6884 - val_loss: 0.7265 - val_accuracy: 0.6931\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7815 - accuracy: 0.6894 - val_loss: 0.6833 - val_accuracy: 0.6986\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7560 - accuracy: 0.6938 - val_loss: 0.6716 - val_accuracy: 0.6919\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7396 - accuracy: 0.6971 - val_loss: 0.6542 - val_accuracy: 0.6946\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7238 - accuracy: 0.7015 - val_loss: 0.6404 - val_accuracy: 0.7104\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7118 - accuracy: 0.7054 - val_loss: 0.6294 - val_accuracy: 0.7121\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7024 - accuracy: 0.7073 - val_loss: 0.6172 - val_accuracy: 0.7132\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6934 - accuracy: 0.7096 - val_loss: 0.6194 - val_accuracy: 0.7068\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6874 - accuracy: 0.7100 - val_loss: 0.6205 - val_accuracy: 0.7172\n",
      "Epoch 23/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.6790 - accuracy: 0.7147 - val_loss: 0.6280 - val_accuracy: 0.7107\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 26s 13ms/step - loss: 1.1351 - accuracy: 0.3293 - val_loss: 1.1114 - val_accuracy: 0.0710\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 1.1096 - accuracy: 0.3276 - val_loss: 1.1070 - val_accuracy: 0.0710\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1015 - accuracy: 0.3396 - val_loss: 1.1007 - val_accuracy: 0.0710\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0866 - accuracy: 0.4413 - val_loss: 1.0541 - val_accuracy: 0.5739\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 18s 9ms/step - loss: 1.0674 - accuracy: 0.5516 - val_loss: 1.0513 - val_accuracy: 0.5685\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0642 - accuracy: 0.5538 - val_loss: 1.0486 - val_accuracy: 0.5507\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0624 - accuracy: 0.5515 - val_loss: 1.0466 - val_accuracy: 0.5579\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0618 - accuracy: 0.5557 - val_loss: 1.0394 - val_accuracy: 0.5606\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 1.0605 - accuracy: 0.5570 - val_loss: 1.0411 - val_accuracy: 0.5650\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0603 - accuracy: 0.5646 - val_loss: 1.0418 - val_accuracy: 0.5679\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0578 - accuracy: 0.5708 - val_loss: 1.0315 - val_accuracy: 0.5833\n",
      "Epoch 12/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0519 - accuracy: 0.5756 - val_loss: 1.0118 - val_accuracy: 0.5939\n",
      "Epoch 13/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.9850 - accuracy: 0.6199 - val_loss: 0.9099 - val_accuracy: 0.6419\n",
      "Epoch 14/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8927 - accuracy: 0.6720 - val_loss: 1.0952 - val_accuracy: 0.4404\n",
      "Epoch 15/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.8383 - accuracy: 0.6876 - val_loss: 0.9321 - val_accuracy: 0.5429\n",
      "Epoch 16/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 0.7999 - accuracy: 0.6871 - val_loss: 0.8887 - val_accuracy: 0.5586\n",
      "Epoch 17/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7750 - accuracy: 0.6898 - val_loss: 0.7777 - val_accuracy: 0.6175\n",
      "Epoch 18/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7526 - accuracy: 0.6940 - val_loss: 0.8073 - val_accuracy: 0.5982\n",
      "Epoch 19/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7345 - accuracy: 0.6991 - val_loss: 0.7379 - val_accuracy: 0.6317\n",
      "Epoch 20/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7240 - accuracy: 0.7024 - val_loss: 0.7881 - val_accuracy: 0.6022\n",
      "Epoch 21/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7148 - accuracy: 0.7034 - val_loss: 0.7480 - val_accuracy: 0.6176\n",
      "Epoch 22/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.7059 - accuracy: 0.7063 - val_loss: 0.7863 - val_accuracy: 0.5971\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 40s 19ms/step - loss: 0.9075 - accuracy: 0.6477 - val_loss: 0.7045 - val_accuracy: 0.7644\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7340 - accuracy: 0.7492 - val_loss: 0.6164 - val_accuracy: 0.7778\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.6671 - accuracy: 0.7770 - val_loss: 0.6112 - val_accuracy: 0.7657\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6024 - accuracy: 0.8061 - val_loss: 0.6057 - val_accuracy: 0.7833\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.5455 - accuracy: 0.8310 - val_loss: 0.6791 - val_accuracy: 0.7825\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.4904 - accuracy: 0.8546 - val_loss: 0.6456 - val_accuracy: 0.7785\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 0.4452 - accuracy: 0.8723 - val_loss: 0.6225 - val_accuracy: 0.8012\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 40s 19ms/step - loss: 1.0078 - accuracy: 0.4419 - val_loss: 0.6959 - val_accuracy: 0.7392\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.7869 - accuracy: 0.6976 - val_loss: 0.6224 - val_accuracy: 0.7429\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.7339 - accuracy: 0.7091 - val_loss: 0.6229 - val_accuracy: 0.7356\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6921 - accuracy: 0.7219 - val_loss: 0.6161 - val_accuracy: 0.7126\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6520 - accuracy: 0.7371 - val_loss: 0.6190 - val_accuracy: 0.7401\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.6137 - accuracy: 0.7567 - val_loss: 0.5896 - val_accuracy: 0.7614\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.5663 - accuracy: 0.7785 - val_loss: 0.5996 - val_accuracy: 0.7539\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 0.5285 - accuracy: 0.7990 - val_loss: 0.5915 - val_accuracy: 0.7893\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 16s 8ms/step - loss: 0.4931 - accuracy: 0.8158 - val_loss: 0.6377 - val_accuracy: 0.7622\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 27s 13ms/step - loss: 1.1469 - accuracy: 0.3280 - val_loss: 1.0824 - val_accuracy: 0.6624\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1031 - accuracy: 0.3217 - val_loss: 1.0892 - val_accuracy: 0.6624\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1012 - accuracy: 0.3218 - val_loss: 1.0874 - val_accuracy: 0.6624\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1007 - accuracy: 0.3269 - val_loss: 1.0842 - val_accuracy: 0.6624\n",
      "Epoch 1/30\n",
      "2025/2025 [==============================] - 27s 13ms/step - loss: 1.1450 - accuracy: 0.3352 - val_loss: 1.0640 - val_accuracy: 0.6624\n",
      "Epoch 2/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1035 - accuracy: 0.3249 - val_loss: 1.0649 - val_accuracy: 0.6624\n",
      "Epoch 3/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1011 - accuracy: 0.3204 - val_loss: 1.0630 - val_accuracy: 0.6624\n",
      "Epoch 4/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.1000 - accuracy: 0.3297 - val_loss: 1.0588 - val_accuracy: 0.6526\n",
      "Epoch 5/30\n",
      "2025/2025 [==============================] - 14s 7ms/step - loss: 1.0908 - accuracy: 0.4271 - val_loss: 1.0184 - val_accuracy: 0.6335\n",
      "Epoch 6/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0712 - accuracy: 0.5472 - val_loss: 1.0169 - val_accuracy: 0.6237\n",
      "Epoch 7/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0666 - accuracy: 0.5502 - val_loss: 1.0151 - val_accuracy: 0.6144\n",
      "Epoch 8/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0651 - accuracy: 0.5517 - val_loss: 1.0067 - val_accuracy: 0.6160\n",
      "Epoch 9/30\n",
      "2025/2025 [==============================] - 15s 8ms/step - loss: 1.0639 - accuracy: 0.5481 - val_loss: 1.0234 - val_accuracy: 0.6092\n",
      "Epoch 10/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0637 - accuracy: 0.5575 - val_loss: 1.0230 - val_accuracy: 0.6115\n",
      "Epoch 11/30\n",
      "2025/2025 [==============================] - 15s 7ms/step - loss: 1.0629 - accuracy: 0.5630 - val_loss: 1.0196 - val_accuracy: 0.6169\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "best_RNN, acc_RNN = grid_search_CNN()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T20:58:54.753670600Z",
     "start_time": "2024-05-19T20:17:58.310390600Z"
    }
   },
   "id": "8410bf9ad050c5f9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7756d6ea51741a37"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100)]             0         \n",
      "                                                                 \n",
      " embedding_7 (Embedding)     (None, 100, 128)          1024000   \n",
      "                                                                 \n",
      " conv1d_12 (Conv1D)          (None, 96, 128)           82048     \n",
      "                                                                 \n",
      " max_pooling1d_12 (MaxPooli  (None, 48, 128)           0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_13 (Conv1D)          (None, 48, 64)            32832     \n",
      "                                                                 \n",
      " max_pooling1d_13 (MaxPooli  (None, 24, 64)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_14 (Conv1D)          (None, 24, 32)            8224      \n",
      "                                                                 \n",
      " max_pooling1d_14 (MaxPooli  (None, 12, 32)            0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " conv1d_15 (Conv1D)          (None, 12, 32)            4128      \n",
      "                                                                 \n",
      " max_pooling1d_15 (MaxPooli  (None, 6, 32)             0         \n",
      " ng1D)                                                           \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 6, 10)             330       \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 6, 10)             0         \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 60)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 183       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1151745 (4.39 MB)\n",
      "Trainable params: 1151745 (4.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "1419/2025 [====================>.........] - ETA: 9s - loss: 0.8580 - accuracy: 0.6433"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[41], line 9\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Train the model (replace with your training and validation data)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m      6\u001B[0m     keras\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mEarlyStopping(monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m'\u001B[39m, patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, min_delta\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.002\u001B[39m, restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[1;32m      7\u001B[0m ]\n\u001B[0;32m----> 9\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcache\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m model\u001B[38;5;241m.\u001B[39mevaluate(test_ds)\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTest dataset accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel\u001B[38;5;241m.\u001B[39mevaluate(test_ds)[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1799\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1800\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1801\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1804\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1805\u001B[0m ):\n\u001B[1;32m   1806\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1807\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1808\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1809\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    829\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    831\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 832\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    834\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    835\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    867\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 868\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    874\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1319\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1320\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1321\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1322\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1323\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_preflattened\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1325\u001B[0m     args,\n\u001B[1;32m   1326\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1327\u001B[0m     executing_eagerly)\n\u001B[1;32m   1328\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001B[0m, in \u001B[0;36mAtomicFunction.call_preflattened\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcall_preflattened\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    215\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 216\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001B[0m, in \u001B[0;36mAtomicFunction.call_flat\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    250\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 251\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    252\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    256\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    257\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    258\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    261\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1484\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1486\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1494\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1495\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1496\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1500\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1501\u001B[0m   )\n",
      "File \u001B[0;32m~/anaconda3/envs/myenv/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     52\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 53\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     54\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     56\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model = create_CNN(max_length)\n",
    "model.summary()\n",
    "\n",
    "# Train the model (replace with your training and validation data)\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, min_delta=0.002, restore_best_weights=True),\n",
    "]\n",
    "\n",
    "history = model.fit(train_ds.cache(), epochs=3, validation_data=val_ds.cache(), callbacks=callbacks)\n",
    "model.evaluate(test_ds)\n",
    "print(f\"Test dataset accuracy: {model.evaluate(test_ds)[1]}\")\n",
    "get_conf_matrix(model)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-19T18:45:02.978788Z",
     "start_time": "2024-05-19T18:44:40.859714300Z"
    }
   },
   "id": "5aaa5fc4ba9bc7ea"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
